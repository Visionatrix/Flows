{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Visionatrix Documentation","text":"<p>Welcome to the Visionatrix project documentation.</p> <p>Here, you will find all the information to get started and understand how the project works.</p> <p>Admin Manual:</p> <ul> <li>Installation</li> <li>Working Modes</li> <li>Command Line Options</li> <li>Environment Variables</li> </ul> <p>Flows Developing:</p> <ul> <li>Vix Workflows</li> <li>Technical Information</li> <li>ComfyUI to Vix Workflows Migration</li> <li>Models Catalog</li> <li>Gated Models</li> </ul> <p>Integrations Manual:</p> <ul> <li>Getting Started</li> </ul> <p>Common information:</p> <ul> <li>FAQ</li> <li>Hardware FAQ</li> <li>Hardware Results</li> <li>Hardware Results (Raw)</li> </ul> <p>Specialized stuff:</p> <ul> <li>How To Perform Benchmarks</li> <li>Swagger API</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#can-i-use-comfyui-which-is-included-in-visionatrix","title":"Can I use ComfyUI which is included in Visionatrix?","text":"<p>Yes, you can install your Nodes there and run ComfyUI separately. You can also tell Visionatrix to use ComfyUI installed in a different path. See the --comfyui_dir parameter.</p>"},{"location":"faq/#can-i-run-it-on-multiple-gpu","title":"Can I run it on multiple GPU?","text":"<p>You can run one worker on one GPU and process tasks in parallel, take a look at Server and Worker modes.</p>"},{"location":"hardware_faq/","title":"Hardware FAQ","text":"<p>First, you can take a look at the information in the ComfyUI repository.</p> <p>Note</p> <p>If you are using Windows and want to avoid hassles, currently, there are no alternatives to Nvidia. PyTorch is expected to release a native version for AMD for Windows soon, but until then, Nvidia is the only option.</p> <p>List of GPUs by usefulness:</p> <ol> <li>Nvidia 4090 <code>24 GB</code></li> <li>AMD 7900 XTX <code>24 GB</code></li> <li>Nvidia 3090 <code>24 GB</code></li> <li>Nvidia 4080 Super <code>16 GB</code></li> <li>Nvidia 4070 Ti Super <code>16 GB</code></li> <li>AMD RX 7900 XT <code>20 GB</code></li> <li>AMD RX 7900 GRE <code>16 GB</code></li> <li>Nvidia 4060 Ti <code>16 GB</code></li> <li>Nvidia 3060 <code>12 GB</code></li> </ol> <p>Note</p> <p>You can also look at any performance tests of hardware for ComfyUI as a reference.</p> <p>Q: Why are there no AMD cards other than AMD 7900 series on the list?</p> <p>A: ROCM (Radeon Open Compute) <code>officially</code> supports only these cards.</p> <p>Q: How much RAM is needed in the system?</p> <p>A: For normal operation, 32 GB is sufficient, but if you want to handle large resolutions with Supir Scaler Workflow, then 64 GB is recommended.</p> <p>Q: How to use 2 GPUs?</p> <p>A: The simplest way is to run 2 workers, each assigned to its own GPU, so they can process tasks in parallel.</p>"},{"location":"hardware_results/","title":"Hardware Benchmark Results Graphs","text":""},{"location":"hardware_results_raw/","title":"Hardware Test Results","text":""},{"location":"hardware_results_raw/#stable-cascade","title":"Stable Cascade","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory 1 pass 6.2 7900X-4070TiS 2025/02/11 NORMALYes 11472 MB 1 pass 6.4 5900X-4090 2025/02/17 NORMALYes 11961 MB 1 pass 6.8 XEON8470-H100 2025/02/22 NORMALYes 13287 MB 1 pass 7.3 EPYC7443-6000A 2025/02/18 NORMALYes 13287 MB 1 pass 7.7 7900X-4070TiS 2025/02/11 NORMALNo 6963 MB 1 pass 7.9 9950X-7900XTX 2025/02/02 NORMALYes 11545 MB 1 pass 8.1 EPYC7513-A100 2025/02/18 NORMALYes 13256 MB 1 pass 8.5 EPYC75F3-3090 2025/02/17 NORMALYes 13287 MB 1 pass 8.5 EPYC7763-6000 2025/02/17 NORMALYes 13144 MB 1 pass 8.9 9950X-7900XTX 2025/02/02 NORMALNo 7008 MB 1 pass 11.0 5900X-4090 2025/02/17 NORMALNo 6961 MB 1 pass 11.4 XEON8470-H100 2025/02/22 NORMALNo 6961 MB 1 pass 11.4 EPYC7443-6000A 2025/02/18 NORMALNo 6961 MB 1 pass 14.8 EPYC75F3-3090 2025/02/17 NORMALNo 6961 MB 1 pass 14.9 EPYC7513-A100 2025/02/18 NORMALNo 6961 MB 1 pass 15.5 EPYC7763-6000 2025/02/17 NORMALNo 6961 MB 2 passes 13.5 XEON8470-H100 2025/02/22 NORMALYes 12750 MB 2 passes 16.2 EPYC7443-6000A 2025/02/18 NORMALYes 12750 MB 2 passes 16.7 EPYC7513-A100 2025/02/18 NORMALYes 12750 MB 2 passes 17.9 5900X-4090 2025/02/17 NORMALYes 11961 MB 2 passes 18.6 7900X-4070TiS 2025/02/11 NORMALYes 11478 MB 2 passes 19.6 EPYC7763-6000 2025/02/17 NORMALYes 12750 MB 2 passes 20.8 7900X-4070TiS 2025/02/11 NORMALNo 7066 MB 2 passes 22.7 9950X-7900XTX 2025/02/02 NORMALYes 11545 MB 2 passes 22.8 5900X-4090 2025/02/17 NORMALNo 7080 MB 2 passes 23.6 XEON8470-H100 2025/02/22 NORMALNo 7120 MB 2 passes 24.4 9950X-7900XTX 2025/02/02 NORMALNo 7072 MB 2 passes 24.4 EPYC7443-6000A 2025/02/18 NORMALNo 7096 MB 2 passes 26.5 EPYC75F3-3090 2025/02/17 NORMALYes 11961 MB 2 passes 29.4 EPYC7513-A100 2025/02/18 NORMALNo 7096 MB 2 passes 31.6 EPYC7763-6000 2025/02/17 NORMALNo 7065 MB 2 passes 33.0 EPYC75F3-3090 2025/02/17 NORMALNo 7065 MB 3 passes 20.7 XEON8470-H100 2025/02/22 NORMALYes 13790 MB 3 passes 27.3 EPYC7513-A100 2025/02/18 NORMALYes 13790 MB 3 passes 30.9 EPYC7443-6000A 2025/02/18 NORMALYes 12748 MB 3 passes 32.9 5900X-4090 2025/02/17 NORMALYes 11961 MB 3 passes 33.8 XEON8470-H100 2025/02/22 NORMALNo 7206 MB 3 passes 37.2 EPYC7763-6000 2025/02/17 NORMALYes 12752 MB 3 passes 37.7 5900X-4090 2025/02/17 NORMALNo 7206 MB 3 passes 38.7 7900X-4070TiS 2025/02/11 NORMALYes 11478 MB 3 passes 40.6 7900X-4070TiS 2025/02/11 NORMALNo 7207 MB 3 passes 41.6 EPYC7443-6000A 2025/02/18 NORMALNo 7206 MB 3 passes 46.1 EPYC7513-A100 2025/02/18 NORMALNo 7206 MB 3 passes 49.4 9950X-7900XTX 2025/02/02 NORMALYes 11545 MB 3 passes 51.0 9950X-7900XTX 2025/02/02 NORMALNo 7206 MB 3 passes 52.1 EPYC75F3-3090 2025/02/17 NORMALYes 11961 MB 3 passes 52.2 EPYC7763-6000 2025/02/17 NORMALNo 7206 MB 3 passes 59.2 EPYC75F3-3090 2025/02/17 NORMALNo 7206 MB"},{"location":"hardware_results_raw/#surprise-me-internal","title":"Surprise Me (Internal)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Generate prompt (falcon3:7b-instruct-fp16) 0.6 XEON8470-H100 2025/02/22 NORMALYes 839 MB Generate prompt (falcon3:7b-instruct-fp16) 0.9 EPYC7513-A100 2025/02/18 NORMALYes 32 MB Generate prompt (falcon3:7b-instruct-fp16) 1.0 5900X-4090 2025/02/17 NORMALYes 840 MB Generate prompt (falcon3:7b-instruct-fp16) 1.2 9950X-7900XTX 2025/02/02 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) 1.3 EPYC7443-6000A 2025/02/18 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) 1.3 EPYC75F3-3090 2025/02/17 NORMALYes 839 MB Generate prompt (falcon3:7b-instruct-fp16) 1.4 EPYC7763-6000 2025/02/17 NORMALYes 838 MB Generate prompt (falcon3:7b-instruct-fp16) 3.2 7900X-4070TiS 2025/02/16 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 4.6 9950X-7900XTX 2025/02/02 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 6.2 EPYC7763-6000 2025/02/17 NORMALYes 838 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 6.2 7900X-4070TiS 2025/02/16 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 6.6 5900X-4090 2025/02/17 NORMALYes 840 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 6.6 EPYC7443-6000A 2025/02/18 NORMALYes 0 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 7.4 XEON8470-H100 2025/02/22 NORMALYes 839 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 8.3 EPYC75F3-3090 2025/02/17 NORMALYes 839 MB Generate prompt (falcon3:7b-instruct-fp16) (unload=True) 8.5 EPYC7513-A100 2025/02/18 NORMALYes 32 MB Generate prompt (phi4:14b-q4_K_M) 0.6 XEON8470-H100 2025/02/22 NORMALYes 839 MB Generate prompt (phi4:14b-q4_K_M) 0.9 5900X-4090 2025/02/17 NORMALYes 840 MB Generate prompt (phi4:14b-q4_K_M) 0.9 EPYC7513-A100 2025/02/18 NORMALYes 32 MB Generate prompt (phi4:14b-q4_K_M) 1.1 EPYC7763-6000 2025/02/17 NORMALYes 838 MB Generate prompt (phi4:14b-q4_K_M) 1.1 7900X-4070TiS 2025/02/16 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) 1.1 9950X-7900XTX 2025/02/02 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) 1.1 EPYC7443-6000A 2025/02/18 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) 1.1 EPYC75F3-3090 2025/02/17 NORMALYes 839 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 3.4 9950X-7900XTX 2025/02/02 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 3.5 EPYC7513-A100 2025/02/18 NORMALYes 32 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 3.5 7900X-4070TiS 2025/02/16 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 3.8 XEON8470-H100 2025/02/22 NORMALYes 839 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 4.0 5900X-4090 2025/02/17 NORMALYes 840 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 4.4 EPYC7443-6000A 2025/02/18 NORMALYes 0 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 4.8 EPYC7763-6000 2025/02/17 NORMALYes 838 MB Generate prompt (phi4:14b-q4_K_M) (unload=True) 5.9 EPYC75F3-3090 2025/02/17 NORMALYes 839 MB"},{"location":"hardware_results_raw/#juggernaut-lite","title":"Juggernaut Lite","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 7.2 XEON8470-H100 2025/02/22 NORMALYes 10886 MB lighting 8.0 XEON8470-H100 2025/02/22 NORMALNo 5267 MB lighting 8.1 5900X-4090 2025/02/17 NORMALYes 8861 MB lighting 8.8 EPYC7443-6000A 2025/02/18 NORMALYes 8840 MB lighting 9.2 EPYC7513-A100 2025/02/18 NORMALYes 9882 MB lighting 9.2 9950X-7900XTX 2025/02/02 NORMALYes 9375 MB lighting 9.3 5900X-4090 2025/02/17 NORMALNo 5267 MB lighting 9.6 7900X-4070TiS 2025/02/11 NORMALYes 9887 MB lighting 9.8 EPYC7443-6000A 2025/02/18 NORMALNo 5267 MB lighting 9.9 9950X-7900XTX 2025/02/02 NORMALNo 6355 MB lighting 10.4 7900X-4070TiS 2025/02/11 NORMALNo 5267 MB lighting 11.3 EPYC7763-6000 2025/02/17 NORMALYes 9882 MB lighting 11.5 EPYC7513-A100 2025/02/18 NORMALNo 5267 MB lighting 11.6 EPYC75F3-3090 2025/02/17 NORMALYes 9859 MB lighting 12.4 EPYC7763-6000 2025/02/17 NORMALNo 5267 MB lighting 12.8 EPYC75F3-3090 2025/02/17 NORMALNo 5267 MB"},{"location":"hardware_results_raw/#aesthetic-images","title":"Aesthetic images","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.7 XEON8470-H100 2025/02/22 NORMALYes 8828 MB default 4.0 5900X-4090 2025/02/17 NORMALYes 8835 MB default 4.7 EPYC7513-A100 2025/02/18 NORMALYes 8854 MB default 4.8 EPYC7443-6000A 2025/02/18 NORMALYes 8828 MB default 5.4 XEON8470-H100 2025/02/22 NORMALNo 5302 MB default 5.7 5900X-4090 2025/02/17 NORMALNo 5302 MB default 5.9 EPYC7763-6000 2025/02/17 NORMALYes 8853 MB default 6.2 EPYC7443-6000A 2025/02/18 NORMALNo 5302 MB default 6.6 7900X-4070TiS 2025/02/11 NORMALYes 8835 MB default 7.0 EPYC7513-A100 2025/02/18 NORMALNo 5302 MB default 7.5 EPYC75F3-3090 2025/02/17 NORMALYes 8827 MB default 8.0 EPYC7763-6000 2025/02/17 NORMALNo 5322 MB default 8.0 9950X-7900XTX 2025/02/02 NORMALYes 9362 MB default 8.6 7900X-4070TiS 2025/02/11 NORMALNo 5302 MB default 9.9 EPYC75F3-3090 2025/02/17 NORMALNo 5322 MB default 10.1 9950X-7900XTX 2025/02/02 NORMALNo 6389 MB fast_run 1.5 XEON8470-H100 2025/02/22 NORMALYes 8835 MB fast_run 1.7 5900X-4090 2025/02/17 NORMALYes 8835 MB fast_run 2.0 EPYC7513-A100 2025/02/18 NORMALYes 8835 MB fast_run 2.0 EPYC7443-6000A 2025/02/18 NORMALYes 8835 MB fast_run 2.3 EPYC7763-6000 2025/02/17 NORMALYes 8834 MB fast_run 2.4 7900X-4070TiS 2025/02/11 NORMALYes 8835 MB fast_run 2.9 EPYC75F3-3090 2025/02/17 NORMALYes 8834 MB fast_run 2.9 9950X-7900XTX 2025/02/02 NORMALYes 9362 MB fast_run 3.3 EPYC7443-6000A 2025/02/18 NORMALNo 5302 MB fast_run 3.3 XEON8470-H100 2025/02/22 NORMALNo 5302 MB fast_run 3.4 5900X-4090 2025/02/17 NORMALNo 5302 MB fast_run 3.9 7900X-4070TiS 2025/02/11 NORMALNo 5302 MB fast_run 4.1 EPYC7763-6000 2025/02/17 NORMALNo 5322 MB fast_run 4.3 EPYC7513-A100 2025/02/18 NORMALNo 5302 MB fast_run 4.5 9950X-7900XTX 2025/02/02 NORMALNo 6389 MB fast_run 5.3 EPYC75F3-3090 2025/02/17 NORMALNo 5322 MB"},{"location":"hardware_results_raw/#sdxl-lighting","title":"SDXL Lighting","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 1.3 XEON8470-H100 2025/02/22 NORMALYes 8907 MB lighting 1.3 5900X-4090 2025/02/17 NORMALYes 8913 MB lighting 1.4 7900X-4070TiS 2025/02/11 NORMALYes 8914 MB lighting 1.5 EPYC7443-6000A 2025/02/18 NORMALYes 8907 MB lighting 1.5 9950X-7900XTX 2025/02/02 NORMALYes 9452 MB lighting 1.7 EPYC7513-A100 2025/02/18 NORMALYes 8930 MB lighting 1.7 EPYC7763-6000 2025/02/17 NORMALYes 8928 MB lighting 1.8 EPYC75F3-3090 2025/02/17 NORMALYes 8907 MB lighting 2.6 7900X-4070TiS 2025/02/11 NORMALNo 5155 MB lighting 2.9 EPYC7443-6000A 2025/02/18 NORMALNo 5155 MB lighting 2.9 XEON8470-H100 2025/02/22 NORMALNo 5155 MB lighting 3.0 9950X-7900XTX 2025/02/02 NORMALNo 5725 MB lighting 3.1 5900X-4090 2025/02/17 NORMALNo 5155 MB lighting 4.1 EPYC7763-6000 2025/02/17 NORMALNo 5163 MB lighting 4.1 EPYC75F3-3090 2025/02/17 NORMALNo 5163 MB lighting 4.2 EPYC7513-A100 2025/02/18 NORMALNo 5155 MB"},{"location":"hardware_results_raw/#hunyuandit","title":"HunyuanDiT","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 4.6 XEON8470-H100 2025/02/22 NORMALYes 9125 MB default 7.0 XEON8470-H100 2025/02/22 NORMALNo 3957 MB default 8.5 5900X-4090 2025/02/17 NORMALYes 9125 MB default 8.9 EPYC7513-A100 2025/02/18 NORMALYes 9102 MB default 10.6 5900X-4090 2025/02/17 NORMALNo 3957 MB default 10.6 EPYC7443-6000A 2025/02/18 NORMALYes 9125 MB default 11.6 EPYC7513-A100 2025/02/18 NORMALNo 3957 MB default 12.3 EPYC7443-6000A 2025/02/18 NORMALNo 3957 MB default 15.0 EPYC7763-6000 2025/02/17 NORMALYes 9102 MB default 16.1 7900X-4070TiS 2025/02/11 NORMALYes 9125 MB default 17.8 EPYC7763-6000 2025/02/17 NORMALNo 3957 MB default 18.1 EPYC75F3-3090 2025/02/17 NORMALYes 9125 MB default 19.1 7900X-4070TiS 2025/02/11 NORMALNo 3957 MB default 20.8 EPYC75F3-3090 2025/02/17 NORMALNo 3957 MB default 31.7 9950X-7900XTX 2025/02/02 NORMALYes 9662 MB default 33.1 9950X-7900XTX 2025/02/02 NORMALNo 3982 MB"},{"location":"hardware_results_raw/#sd35-large","title":"SD3.5 Large","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 6.8 XEON8470-H100 2025/02/22 NORMALYes 28795 MB default 13.3 EPYC7513-A100 2025/02/18 NORMALYes 28795 MB default 21.0 EPYC7443-6000A 2025/02/18 NORMALYes 28792 MB default 21.8 5900X-4090 2025/02/17 NORMALYes 22289 MB default 23.5 XEON8470-H100 2025/02/22 NORMALNo 16636 MB default 25.2 EPYC7763-6000 2025/02/17 NORMALYes 28795 MB default 29.5 5900X-4090 2025/02/17 NORMALNo 16637 MB default 34.2 EPYC7443-6000A 2025/02/18 NORMALNo 16637 MB default 36.6 EPYC7513-A100 2025/02/18 NORMALNo 16637 MB default 39.2 EPYC75F3-3090 2025/02/17 NORMALYes 22689 MB default 45.5 7900X-4070TiS 2025/02/11 NORMALYes 14609 MB default 46.3 9950X-7900XTX 2025/02/02 NORMALYes 22207 MB default 46.6 EPYC7763-6000 2025/02/17 NORMALNo 16636 MB default 48.3 7900X-4070TiS 2025/02/11 NORMALNo 14460 MB default 49.4 9950X-7900XTX 2025/02/02 NORMALNo 16635 MB default 50.7 EPYC75F3-3090 2025/02/17 NORMALNo 16636 MB"},{"location":"hardware_results_raw/#sd35-medium","title":"SD3.5 Medium","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.5 XEON8470-H100 2025/02/22 NORMALYes 17800 MB default 6.4 EPYC7513-A100 2025/02/18 NORMALYes 17800 MB default 6.5 5900X-4090 2025/02/17 NORMALYes 17807 MB default 7.9 EPYC7443-6000A 2025/02/18 NORMALYes 17799 MB default 10.7 EPYC7763-6000 2025/02/17 NORMALYes 17800 MB default 12.8 5900X-4090 2025/02/17 NORMALNo 10865 MB default 13.0 EPYC75F3-3090 2025/02/17 NORMALYes 17800 MB default 13.5 EPYC7443-6000A 2025/02/18 NORMALNo 10865 MB default 14.0 7900X-4070TiS 2025/02/11 NORMALYes 14608 MB default 14.7 XEON8470-H100 2025/02/22 NORMALNo 10865 MB default 17.6 EPYC7513-A100 2025/02/18 NORMALNo 10865 MB default 17.6 7900X-4070TiS 2025/02/11 NORMALNo 10865 MB default 19.1 9950X-7900XTX 2025/02/02 NORMALYes 16568 MB default 21.5 EPYC75F3-3090 2025/02/17 NORMALNo 10865 MB default 22.5 EPYC7763-6000 2025/02/17 NORMALNo 10865 MB default 22.6 9950X-7900XTX 2025/02/02 NORMALNo 10865 MB"},{"location":"hardware_results_raw/#flux-lighting","title":"Flux Lighting","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 1.2 XEON8470-H100 2025/02/22 NORMALYes 34384 MB lighting 2.3 EPYC7513-A100 2025/02/18 NORMALYes 34384 MB lighting 3.4 EPYC7443-6000A 2025/02/18 NORMALYes 34384 MB lighting 4.1 EPYC7763-6000 2025/02/17 NORMALYes 34384 MB lighting 12.9 5900X-4090 2025/02/17 NORMALYes 22404 MB lighting 13.0 9950X-7900XTX 2025/02/02 NORMALYes 22306 MB lighting 17.1 9950X-7900XTX 2025/02/02 NORMALNo 23162 MB lighting 17.3 7900X-4070TiS 2025/02/11 NORMALYes 14432 MB lighting 19.3 7900X-4070TiS 2025/02/11 NORMALNo 14285 MB lighting 19.5 EPYC75F3-3090 2025/02/17 NORMALYes 22725 MB lighting 20.3 5900X-4090 2025/02/17 NORMALNo 22404 MB lighting 22.5 EPYC7443-6000A 2025/02/18 NORMALNo 23257 MB lighting 28.3 XEON8470-H100 2025/02/22 NORMALNo 23257 MB lighting 30.0 EPYC75F3-3090 2025/02/17 NORMALNo 22725 MB lighting 34.0 EPYC7763-6000 2025/02/17 NORMALNo 23257 MB lighting 37.9 EPYC7513-A100 2025/02/18 NORMALNo 23257 MB"},{"location":"hardware_results_raw/#pixart-sigma","title":"PixArt Sigma","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.4 XEON8470-H100 2025/02/22 NORMALYes 13200 MB default 5.6 EPYC7513-A100 2025/02/18 NORMALYes 13200 MB default 5.9 5900X-4090 2025/02/17 NORMALYes 13200 MB default 7.1 EPYC7443-6000A 2025/02/18 NORMALYes 13200 MB default 9.5 EPYC7763-6000 2025/02/17 NORMALYes 13200 MB default 9.8 XEON8470-H100 2025/02/22 NORMALNo 9282 MB default 10.6 7900X-4070TiS 2025/02/11 NORMALYes 12656 MB default 10.9 5900X-4090 2025/02/17 NORMALNo 9282 MB default 11.7 EPYC7443-6000A 2025/02/18 NORMALNo 9282 MB default 12.3 EPYC75F3-3090 2025/02/17 NORMALYes 13200 MB default 13.9 EPYC7513-A100 2025/02/18 NORMALNo 9282 MB default 15.2 7900X-4070TiS 2025/02/11 NORMALNo 9282 MB default 16.2 EPYC7763-6000 2025/02/17 NORMALNo 9282 MB default 18.7 EPYC75F3-3090 2025/02/17 NORMALNo 9282 MB default 26.1 9950X-7900XTX 2025/02/02 NORMALYes 13735 MB default 28.8 9950X-7900XTX 2025/02/02 NORMALNo 9282 MB"},{"location":"hardware_results_raw/#flux","title":"Flux","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 6.9 XEON8470-H100 2025/02/22 NORMALYes 34403 MB default 13.5 EPYC7513-A100 2025/02/18 NORMALYes 34403 MB default 22.7 EPYC7443-6000A 2025/02/18 NORMALYes 34403 MB default 27.5 EPYC7763-6000 2025/02/17 NORMALYes 34403 MB default 29.9 5900X-4090 2025/02/17 NORMALYes 22404 MB default 32.0 XEON8470-H100 2025/02/22 NORMALNo 23278 MB default 37.4 5900X-4090 2025/02/17 NORMALNo 22404 MB default 41.1 EPYC7443-6000A 2025/02/18 NORMALNo 23278 MB default 44.8 EPYC7513-A100 2025/02/18 NORMALNo 24084 MB default 51.3 EPYC75F3-3090 2025/02/17 NORMALYes 22725 MB default 54.5 9950X-7900XTX 2025/02/02 NORMALYes 22306 MB default 55.6 EPYC7763-6000 2025/02/17 NORMALNo 23278 MB default 59.3 9950X-7900XTX 2025/02/02 NORMALNo 23165 MB default 60.2 7900X-4070TiS 2025/02/11 NORMALYes 14383 MB default 61.5 EPYC75F3-3090 2025/02/17 NORMALNo 22725 MB default 64.7 7900X-4070TiS 2025/02/11 NORMALNo 14297 MB"},{"location":"hardware_results_raw/#remove-background-birefnet-lite","title":"Remove background (BiRefNet Lite)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Remove Background 0.6 9950X-7900XTX 2025/02/02 NORMALNo 2523 MB Remove Background 0.7 9950X-7900XTX 2025/02/02 NORMALYes 2518 MB Remove Background 0.9 7900X-4070TiS 2025/02/11 NORMALNo 2744 MB Remove Background 1.0 EPYC7763-6000 2025/02/17 NORMALNo 2639 MB Remove Background 1.1 7900X-4070TiS 2025/02/11 NORMALYes 1943 MB Remove Background 1.2 EPYC7763-6000 2025/02/17 NORMALYes 1711 MB Remove Background 1.3 XEON8470-H100 2025/02/22 NORMALYes 2635 MB Remove Background 1.3 XEON8470-H100 2025/02/22 NORMALNo 2639 MB Remove Background 1.9 EPYC7443-6000A 2025/02/18 NORMALYes 2641 MB Remove Background 1.9 EPYC7443-6000A 2025/02/18 NORMALNo 2639 MB Remove Background 1.9 5900X-4090 2025/02/17 NORMALYes 2638 MB Remove Background 1.9 5900X-4090 2025/02/17 NORMALNo 2638 MB Remove Background 1.9 EPYC7513-A100 2025/02/18 NORMALYes 1712 MB Remove Background 1.9 EPYC7513-A100 2025/02/18 NORMALNo 2523 MB Remove Background 2.1 EPYC75F3-3090 2025/02/17 NORMALYes 2637 MB Remove Background 2.1 EPYC75F3-3090 2025/02/17 NORMALNo 2639 MB"},{"location":"hardware_results_raw/#remove-background-birefnet","title":"Remove background (BiRefNet)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Remove Background 0.7 9950X-7900XTX 2025/02/02 NORMALYes 4026 MB Remove Background 0.7 9950X-7900XTX 2025/02/02 NORMALNo 4029 MB Remove Background 1.1 7900X-4070TiS 2025/02/11 NORMALYes 3219 MB Remove Background 1.1 7900X-4070TiS 2025/02/11 NORMALNo 4030 MB Remove Background 1.2 EPYC7763-6000 2025/02/17 NORMALYes 3218 MB Remove Background 1.2 EPYC7763-6000 2025/02/17 NORMALNo 4029 MB Remove Background 1.3 XEON8470-H100 2025/02/22 NORMALYes 4025 MB Remove Background 1.3 XEON8470-H100 2025/02/22 NORMALNo 4026 MB Remove Background 1.9 EPYC7443-6000A 2025/02/18 NORMALNo 4029 MB Remove Background 1.9 5900X-4090 2025/02/17 NORMALYes 4027 MB Remove Background 2.0 EPYC7443-6000A 2025/02/18 NORMALYes 4030 MB Remove Background 2.0 5900X-4090 2025/02/17 NORMALNo 4027 MB Remove Background 2.0 EPYC7513-A100 2025/02/18 NORMALYes 3218 MB Remove Background 2.0 EPYC7513-A100 2025/02/18 NORMALNo 4029 MB Remove Background 2.2 EPYC75F3-3090 2025/02/17 NORMALYes 4026 MB Remove Background 2.2 EPYC75F3-3090 2025/02/17 NORMALNo 4029 MB"},{"location":"hardware_results_raw/#pencil-sketch","title":"Pencil Sketch","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 3.4 XEON8470-H100 2025/02/22 NORMALYes 18523 MB lighting 5.8 EPYC7513-A100 2025/02/18 NORMALYes 29858 MB lighting 7.9 5900X-4090 2025/02/17 NORMALYes 18523 MB lighting 8.1 XEON8470-H100 2025/02/22 NORMALNo 11941 MB lighting 9.5 EPYC7443-6000A 2025/02/18 NORMALYes 18523 MB lighting 9.5 EPYC7513-A100 2025/02/18 NORMALNo 23276 MB lighting 11.1 EPYC7763-6000 2025/02/17 NORMALYes 29858 MB lighting 13.5 5900X-4090 2025/02/17 NORMALNo 11941 MB lighting 14.8 EPYC7443-6000A 2025/02/18 NORMALNo 11941 MB lighting 15.3 EPYC75F3-3090 2025/02/17 NORMALYes 18523 MB lighting 18.0 7900X-4070TiS 2025/02/11 NORMALYes 13599 MB lighting 21.1 7900X-4070TiS 2025/02/11 NORMALNo 11940 MB lighting 21.5 9950X-7900XTX 2025/02/02 NORMALYes 17134 MB lighting 22.1 EPYC7763-6000 2025/02/17 NORMALNo 23276 MB lighting 23.3 EPYC75F3-3090 2025/02/17 NORMALNo 11941 MB lighting 24.4 9950X-7900XTX 2025/02/02 NORMALNo 12016 MB"},{"location":"hardware_results_raw/#sd35-large-small","title":"SD3.5 Large (Small)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 6.7 XEON8470-H100 2025/02/22 NORMALYes 27134 MB default 13.1 5900X-4090 2025/02/17 NORMALYes 20585 MB default 14.4 EPYC7443-6000A 2025/02/18 NORMALYes 27134 MB default 14.9 EPYC7513-A100 2025/02/18 NORMALYes 27141 MB default 17.3 XEON8470-H100 2025/02/22 NORMALNo 10865 MB default 21.4 5900X-4090 2025/02/17 NORMALNo 10865 MB default 23.0 EPYC7443-6000A 2025/02/18 NORMALNo 10865 MB default 27.0 EPYC7763-6000 2025/02/17 NORMALYes 27141 MB default 28.7 7900X-4070TiS 2025/02/11 NORMALYes 14313 MB default 28.8 EPYC7513-A100 2025/02/18 NORMALNo 10865 MB default 30.5 7900X-4070TiS 2025/02/11 NORMALNo 10866 MB default 33.2 EPYC75F3-3090 2025/02/17 NORMALYes 20895 MB default 43.9 EPYC7763-6000 2025/02/17 NORMALNo 10865 MB default 44.7 EPYC75F3-3090 2025/02/17 NORMALNo 10865 MB default 45.8 9950X-7900XTX 2025/02/02 NORMALYes 19779 MB default 48.4 9950X-7900XTX 2025/02/02 NORMALNo 10865 MB"},{"location":"hardware_results_raw/#flux-lighting-small","title":"Flux Lighting (Small)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 1.4 XEON8470-H100 2025/02/22 NORMALYes 18650 MB lighting 2.6 EPYC7513-A100 2025/02/18 NORMALYes 18650 MB lighting 2.9 5900X-4090 2025/02/17 NORMALYes 18650 MB lighting 3.5 EPYC7443-6000A 2025/02/18 NORMALYes 18650 MB lighting 4.4 EPYC7763-6000 2025/02/17 NORMALYes 18650 MB lighting 5.5 EPYC75F3-3090 2025/02/17 NORMALYes 18650 MB lighting 7.6 7900X-4070TiS 2025/02/11 NORMALYes 13956 MB lighting 8.7 9950X-7900XTX 2025/02/02 NORMALYes 17281 MB lighting 9.0 5900X-4090 2025/02/17 NORMALNo 12080 MB lighting 10.0 EPYC7443-6000A 2025/02/18 NORMALNo 12080 MB lighting 10.4 XEON8470-H100 2025/02/22 NORMALNo 12080 MB lighting 11.2 7900X-4070TiS 2025/02/11 NORMALNo 12073 MB lighting 11.4 9950X-7900XTX 2025/02/02 NORMALNo 12156 MB lighting 12.8 EPYC7513-A100 2025/02/18 NORMALNo 12080 MB lighting 14.5 EPYC75F3-3090 2025/02/17 NORMALNo 12080 MB lighting 15.0 EPYC7763-6000 2025/02/17 NORMALNo 12080 MB"},{"location":"hardware_results_raw/#flux-small","title":"Flux (Small)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 7.9 XEON8470-H100 2025/02/22 NORMALYes 18636 MB default 15.5 EPYC7513-A100 2025/02/18 NORMALYes 18636 MB default 19.0 5900X-4090 2025/02/17 NORMALYes 18636 MB default 19.2 XEON8470-H100 2025/02/22 NORMALNo 12053 MB default 23.5 EPYC7443-6000A 2025/02/18 NORMALYes 18636 MB default 26.2 5900X-4090 2025/02/17 NORMALNo 12053 MB default 27.3 EPYC7513-A100 2025/02/18 NORMALNo 12053 MB default 29.2 EPYC7763-6000 2025/02/17 NORMALYes 18636 MB default 31.0 EPYC7443-6000A 2025/02/18 NORMALNo 12053 MB default 37.4 EPYC75F3-3090 2025/02/17 NORMALYes 18636 MB default 38.1 7900X-4070TiS 2025/02/11 NORMALYes 13952 MB default 41.7 EPYC7763-6000 2025/02/17 NORMALNo 12053 MB default 43.2 7900X-4070TiS 2025/02/11 NORMALNo 12052 MB default 47.3 EPYC75F3-3090 2025/02/17 NORMALNo 12053 MB default 50.1 9950X-7900XTX 2025/02/02 NORMALYes 17254 MB default 52.8 9950X-7900XTX 2025/02/02 NORMALNo 12129 MB"},{"location":"hardware_results_raw/#supir-upscaler","title":"SUPIR Upscaler","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory 1024x1024 - 1.5x scaling 72.2 5900X-4090 2025/02/17 NORMALYes 9409 MB 1024x1024 - 1.5x scaling 72.3 5900X-4090 2025/02/17 NORMALNo 9409 MB 1024x1024 - 1.5x scaling 74.7 XEON8470-H100 2025/02/22 NORMALNo 9410 MB 1024x1024 - 1.5x scaling 76.0 XEON8470-H100 2025/02/22 NORMALYes 9408 MB 1024x1024 - 1.5x scaling 76.7 EPYC7443-6000A 2025/02/18 NORMALNo 9407 MB 1024x1024 - 1.5x scaling 87.2 EPYC7443-6000A 2025/02/18 NORMALYes 9409 MB 1024x1024 - 1.5x scaling 92.2 7900X-4070TiS 2025/02/11 NORMALYes 8601 MB 1024x1024 - 1.5x scaling 92.8 7900X-4070TiS 2025/02/11 NORMALNo 9398 MB 1024x1024 - 1.5x scaling 93.0 EPYC7513-A100 2025/02/18 NORMALYes 9407 MB 1024x1024 - 1.5x scaling 97.7 9950X-7900XTX 2025/02/02 NORMALNo 9407 MB 1024x1024 - 1.5x scaling 98.1 EPYC7513-A100 2025/02/18 NORMALNo 9407 MB 1024x1024 - 1.5x scaling 98.4 9950X-7900XTX 2025/02/02 NORMALYes 9401 MB 1024x1024 - 1.5x scaling 108.2 EPYC7763-6000 2025/02/17 NORMALNo 9407 MB 1024x1024 - 1.5x scaling 108.4 EPYC7763-6000 2025/02/17 NORMALYes 8601 MB 1024x1024 - 1.5x scaling 114.0 EPYC75F3-3090 2025/02/17 NORMALYes 9408 MB 1024x1024 - 1.5x scaling 114.7 EPYC75F3-3090 2025/02/17 NORMALNo 9407 MB 1024x1024 - 2x scaling 144.7 5900X-4090 2025/02/17 NORMALYes 9413 MB 1024x1024 - 2x scaling 146.8 5900X-4090 2025/02/17 NORMALNo 9413 MB 1024x1024 - 2x scaling 147.6 XEON8470-H100 2025/02/22 NORMALNo 9414 MB 1024x1024 - 2x scaling 154.2 XEON8470-H100 2025/02/22 NORMALYes 9412 MB 1024x1024 - 2x scaling 158.2 EPYC7443-6000A 2025/02/18 NORMALNo 9411 MB 1024x1024 - 2x scaling 160.6 EPYC7443-6000A 2025/02/18 NORMALYes 9413 MB 1024x1024 - 2x scaling 185.7 EPYC7513-A100 2025/02/18 NORMALYes 9411 MB 1024x1024 - 2x scaling 193.3 EPYC7513-A100 2025/02/18 NORMALNo 9411 MB 1024x1024 - 2x scaling 193.7 7900X-4070TiS 2025/02/11 NORMALYes 8604 MB 1024x1024 - 2x scaling 195.9 7900X-4070TiS 2025/02/11 NORMALNo 9402 MB 1024x1024 - 2x scaling 208.4 9950X-7900XTX 2025/02/02 NORMALYes 9405 MB 1024x1024 - 2x scaling 208.7 9950X-7900XTX 2025/02/02 NORMALNo 9411 MB 1024x1024 - 2x scaling 221.5 EPYC7763-6000 2025/02/17 NORMALYes 8605 MB 1024x1024 - 2x scaling 228.4 EPYC7763-6000 2025/02/17 NORMALNo 9411 MB 1024x1024 - 2x scaling 236.2 EPYC75F3-3090 2025/02/17 NORMALYes 9412 MB 1024x1024 - 2x scaling 238.9 EPYC75F3-3090 2025/02/17 NORMALNo 9411 MB"},{"location":"hardware_results_raw/#auraflow","title":"AuraFlow","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 7.0 XEON8470-H100 2025/02/22 NORMALYes 17790 MB default 14.4 EPYC7513-A100 2025/02/18 NORMALYes 17790 MB default 15.5 XEON8470-H100 2025/02/22 NORMALNo 13742 MB default 19.7 5900X-4090 2025/02/17 NORMALYes 17790 MB default 24.9 EPYC7513-A100 2025/02/18 NORMALNo 13742 MB default 26.2 EPYC7443-6000A 2025/02/18 NORMALYes 17790 MB default 27.6 5900X-4090 2025/02/17 NORMALNo 13742 MB default 30.0 EPYC7763-6000 2025/02/17 NORMALYes 17790 MB default 33.2 EPYC7443-6000A 2025/02/18 NORMALNo 13742 MB default 37.5 7900X-4070TiS 2025/02/11 NORMALYes 13742 MB default 40.8 EPYC75F3-3090 2025/02/17 NORMALYes 17790 MB default 42.0 EPYC7763-6000 2025/02/17 NORMALNo 13742 MB default 44.6 7900X-4070TiS 2025/02/11 NORMALNo 13434 MB default 50.5 EPYC75F3-3090 2025/02/17 NORMALNo 13742 MB default 52.1 9950X-7900XTX 2025/02/02 NORMALYes 16719 MB default 61.9 9950X-7900XTX 2025/02/02 NORMALNo 14148 MB"},{"location":"hardware_results_raw/#ghibli-portrait","title":"Ghibli Portrait","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 2.4 5900X-4090 2025/02/17 NORMALYes 12058 MB default 2.6 XEON8470-H100 2025/02/22 NORMALYes 12039 MB default 2.7 EPYC7443-6000A 2025/02/18 NORMALYes 12037 MB default 3.0 EPYC7513-A100 2025/02/18 NORMALYes 12072 MB default 3.1 7900X-4070TiS 2025/02/11 NORMALYes 12037 MB default 3.7 9950X-7900XTX 2025/02/02 NORMALYes 12584 MB default 4.0 EPYC75F3-3090 2025/02/17 NORMALYes 12039 MB default 4.0 5900X-4090 2025/02/17 NORMALNo 8575 MB default 4.5 EPYC7763-6000 2025/02/17 NORMALYes 12064 MB default 4.6 7900X-4070TiS 2025/02/11 NORMALNo 8564 MB default 4.7 EPYC7443-6000A 2025/02/18 NORMALNo 8574 MB default 4.8 XEON8470-H100 2025/02/22 NORMALNo 8571 MB default 5.3 9950X-7900XTX 2025/02/02 NORMALNo 9662 MB default 5.7 EPYC7513-A100 2025/02/18 NORMALNo 8574 MB default 6.8 EPYC75F3-3090 2025/02/17 NORMALNo 8572 MB default 8.2 EPYC7763-6000 2025/02/17 NORMALNo 8571 MB"},{"location":"hardware_results_raw/#vintage-portrait","title":"Vintage Portrait","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 13.4 XEON8470-H100 2025/02/22 NORMALYes 12056 MB default 14.5 5900X-4090 2025/02/17 NORMALYes 12065 MB default 15.6 XEON8470-H100 2025/02/22 NORMALNo 8604 MB default 16.3 5900X-4090 2025/02/17 NORMALNo 8604 MB default 16.5 EPYC7443-6000A 2025/02/18 NORMALYes 12058 MB default 16.7 EPYC7513-A100 2025/02/18 NORMALYes 12083 MB default 17.5 EPYC7443-6000A 2025/02/18 NORMALNo 8605 MB default 18.7 7900X-4070TiS 2025/02/11 NORMALYes 12058 MB default 19.8 EPYC7513-A100 2025/02/18 NORMALNo 8605 MB default 20.6 7900X-4070TiS 2025/02/11 NORMALNo 8603 MB default 20.6 EPYC7763-6000 2025/02/17 NORMALYes 12058 MB default 22.4 9950X-7900XTX 2025/02/02 NORMALYes 12592 MB default 24.2 EPYC75F3-3090 2025/02/17 NORMALYes 12058 MB default 25.4 9950X-7900XTX 2025/02/02 NORMALNo 9693 MB default 27.3 EPYC75F3-3090 2025/02/17 NORMALNo 8605 MB default 32.9 EPYC7763-6000 2025/02/17 NORMALNo 8604 MB"},{"location":"hardware_results_raw/#photo-stickers","title":"Photo Stickers","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 29.3 XEON8470-H100 2025/02/22 NORMALYes 13132 MB default 29.5 5900X-4090 2025/02/17 NORMALYes 13148 MB default 31.0 EPYC7443-6000A 2025/02/18 NORMALYes 13147 MB default 31.1 7900X-4070TiS 2025/02/11 NORMALYes 12625 MB default 32.0 XEON8470-H100 2025/02/22 NORMALNo 9438 MB default 33.7 EPYC7443-6000A 2025/02/18 NORMALNo 9439 MB default 34.0 5900X-4090 2025/02/17 NORMALNo 9434 MB default 34.4 EPYC7513-A100 2025/02/18 NORMALYes 13124 MB default 34.5 9950X-7900XTX 2025/02/02 NORMALYes 13545 MB default 35.0 7900X-4070TiS 2025/02/11 NORMALNo 9429 MB default 36.5 9950X-7900XTX 2025/02/02 NORMALNo 10606 MB default 41.1 EPYC7513-A100 2025/02/18 NORMALNo 9439 MB default 44.5 EPYC75F3-3090 2025/02/17 NORMALYes 13149 MB default 44.5 EPYC7763-6000 2025/02/17 NORMALNo 9469 MB default 45.2 EPYC7763-6000 2025/02/17 NORMALYes 13127 MB default 49.9 EPYC75F3-3090 2025/02/17 NORMALNo 9469 MB"},{"location":"hardware_results_raw/#photo-from-1-image","title":"Photo from 1 image","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 5.6 XEON8470-H100 2025/02/22 NORMALYes 8908 MB default 7.3 EPYC7443-6000A 2025/02/18 NORMALYes 8913 MB default 7.6 EPYC7513-A100 2025/02/18 NORMALYes 8903 MB default 8.6 5900X-4090 2025/02/17 NORMALYes 8914 MB default 8.9 EPYC7763-6000 2025/02/17 NORMALYes 8908 MB default 8.9 XEON8470-H100 2025/02/22 NORMALNo 5310 MB default 9.2 7900X-4070TiS 2025/02/11 NORMALYes 8913 MB default 10.1 EPYC7443-6000A 2025/02/18 NORMALNo 5310 MB default 10.8 EPYC75F3-3090 2025/02/17 NORMALYes 8913 MB default 11.2 5900X-4090 2025/02/17 NORMALNo 5331 MB default 11.7 EPYC7513-A100 2025/02/18 NORMALNo 5310 MB default 12.2 7900X-4070TiS 2025/02/11 NORMALNo 5307 MB default 12.2 9950X-7900XTX 2025/02/02 NORMALYes 9455 MB default 12.5 EPYC7763-6000 2025/02/17 NORMALNo 5331 MB default 14.2 9950X-7900XTX 2025/02/02 NORMALNo 6480 MB default 15.7 EPYC75F3-3090 2025/02/17 NORMALNo 5331 MB"},{"location":"how_to_benchmark/","title":"Introduction","text":"<p>Note</p> <p>For benchmarking, it's preferable to use the <code>SERVER</code> + <code>WORKER</code> modes.</p> <p>You can find the guide on how to install this configuration here.</p> <p>Assuming you have Visionatrix installed, you can proceed with benchmarking.</p> <p>You don't need to run the benchmark script on the same machine where Visionatrix is installed. Therefore, clone the Visionatrix documentation repository wherever it's convenient for you:</p> <pre><code>git clone https://github.com/Visionatrix/VixFlowsDocs.git\n</code></pre>"},{"location":"how_to_benchmark/#setting-up-a-virtual-environment-optional","title":"Setting Up a Virtual Environment (Optional)","text":"<p>It's recommended to use a virtual environment to avoid conflicts with other Python packages on your system. Here's how you can set up a virtual environment that works on macOS and Linux (assuming all necessary OS packages are installed):</p> <pre><code>cd VixFlowsDocs &amp;&amp; python3 -m venv venv &amp;&amp; source venv/bin/activate\n</code></pre> <p>This creates a new virtual environment named <code>venv</code> and activates it. You can now proceed to install the dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>If you prefer not to use a virtual environment, you can install the dependencies directly:</p> <pre><code>cd VixFlowsDocs &amp;&amp; pip install -r requirements.txt\n</code></pre>"},{"location":"how_to_benchmark/#installing-ollama","title":"Installing Ollama","text":"<p>Since Visionatrix is starting to use LLM more and more, we decided to add Ollama tests to help people understand what they can expect.</p> <p>To install Ollama on Linux if it is not installed use:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre> <p>The tests are done with two models:</p> <ul> <li>falcon3:7b-instruct-fp16</li> <li>phi4:14b-q4_K_M</li> </ul> <p>Please install both of these models in Ollama using the commands:</p> <pre><code>ollama pull falcon3:7b-instruct-fp16\nollama pull phi4:14b-q4_K_M\n</code></pre>"},{"location":"how_to_benchmark/#huggingface-and-civitai-tokens","title":"HuggingFace and CivitAI tokens","text":"<p>Make sure that in the Visionatrix Settings, the Hugging Face and CivitAI tokens are present to install the following models used in the flows that are included in the benchmarks:</p> <ul> <li>Shou Xin</li> <li>StableDiffusion 3.5 Medium</li> <li>StableDiffusion 3.5 Large</li> </ul>"},{"location":"how_to_benchmark/#running-the-benchmark-script","title":"Running the Benchmark Script","text":"<p>The benchmark script is located in the <code>scripts/benchmarks</code> directory.</p> <p>You can run the script with the default parameters. The working directory doesn't matter because the script uses relative paths from its own location.</p> <p>If your Visionatrix instance does not have authentication enabled (for example, it's running in <code>DEFAULT</code> mode), simply run the script:</p> <pre><code>python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>The script will prompt you to select the test suite(s) you want to run. Enter the number(s) corresponding to your choice:</p> <pre><code>Please select the test suites you want to run:\n1. SDXL Suite\n2. AURA_FLOW Suite\n3. CASCADE Suite\n4. DIT_8_BIT(FLUX 8-bit, ..) Suite\n5. DIT(Flux original, ..) Suite\n6. PORTRAITS Suite\n7. UPSCALERS Suite\n8. OTHER Suite\n9. OLLAMA Suite\nEnter the numbers of the suites to run, separated by commas (e.g., 1,3,5): 1,2,3,4,5 or `ALL`\n</code></pre> <p>Note</p> <p>The script will automatically install the flows from the selected test suite if they are not already installed. It will start testing as soon as all flows are installed.</p> <p>Upon completion of the tests, a folder with results will appear in the <code>results</code> directory, named with the date, hardware, and test suite. For example:</p> <pre><code>results/2024-11-11-EPYC75F3-4090-SDXL/\n</code></pre> <p>Inside this folder, you will find the summary JSON file (e.g., <code>summary-2024-11-11-EPYC75F3-4090-SDXL.json</code>) and the detailed results for each flow and test case.</p> <p>The <code>benchmark.py</code> script supports resuming interrupted tests. If you run the script again for the same test suite, it will skip tests that have already been completed.</p> <p>You should set the environment variable <code>HARDWARE</code> in the format <code>\"CPU-GPU\"</code> before running the script. If you forget to set it, you can rename the results folder and summary file after the tests are complete to include your hardware specifications.</p> <p>If you want to add your results to the documentation, copy the summary JSON file to the <code>hardware_results</code> folder and open a pull request with this file.</p>"},{"location":"how_to_benchmark/#generating-hardware-results-table","title":"Generating Hardware Results Table","text":"<p>After running the benchmark and collecting results, you can generate a Markdown table summarizing the hardware test results using the <code>generate_hardware_results.py</code> script located in the <code>scripts/benchmarks</code> directory.</p> <p>First, copy the files generated by the benchmark (e.g., <code>summary-2024-11-13-YOUR_CPU-YOUR_GPU-SDXL.json</code>) to the <code>hardware_results</code> folder.</p> <p>Then, run the script to generate the <code>hardware_results.md</code> file:</p> <pre><code>python3 scripts/benchmarks/generate_hardware_results.py\n</code></pre> <p>This script will process the summary JSON files in the <code>hardware_results</code> folder and generate a Markdown table saved as <code>hardware_results.md</code>.</p>"},{"location":"how_to_benchmark/#supported-environment-variables","title":"Supported Environment Variables","text":"<p>As mentioned earlier, the <code>HARDWARE</code> variable is supported. Example usage:</p> <pre><code>HARDWARE=\"EPYC75F3-4090\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>Another supported variable is <code>SERVER_URL</code>, for example:</p> <pre><code>SERVER_URL=\"http://192.168.1.10:8288\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>Use this when Visionatrix is located on another machine.</p> <p>If you need to provide authentication credentials for the Visionatrix server, you can do so using the variables <code>USER_NAME</code> and <code>USER_PASSWORD</code>.</p> <p>Example usage along with <code>SERVER_URL</code>:</p> <pre><code>SERVER_URL=\"http://192.168.1.10:8288\" USER_NAME=\"admin\" USER_PASSWORD=\"admin\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>The <code>COUNT</code> variable controls the number of tasks created for each test case. By default, it is set to <code>2</code>. You can set it to <code>1</code>, <code>3</code>, <code>4</code>, etc. The higher the number, the more accurate the hardware test will be.</p> <p>Another supported variable is <code>REMOVE_RESULTS</code>. By default, it is <code>1</code>, which means the tasks created during testing will be deleted from Visionatrix after completion. You can set it to <code>0</code> if you don't want the tasks to be deleted.</p> <p>If you have a slow internet connection and not all flows from your selected test suite are installed, you might want to set a custom value for the <code>FLOW_INSTALL_TIMEOUT</code> variable.</p> <p>By default, it is set to 2400 seconds (40 minutes). If the flow does not download within this time, the script will produce an error (but this does not cancel the flow installation; it will eventually be installed on the server).</p> <p>The variables <code>PAUSE_INTERVAL</code> (default value <code>0</code>) and <code>PAUSE_INTERVAL_AFTER_WARMUP</code> (default value <code>0</code>) control the pause time between tests.</p> <ul> <li> <p>The <code>PAUSE_INTERVAL</code> variable defines the pause time in seconds between test cases (useful if your device heats up and you want to prevent overheating).</p> </li> <li> <p>The <code>PAUSE_INTERVAL_AFTER_WARMUP</code> variable defines the interval of time to wait after the warm-up run. During the warm-up, models are loaded into memory. This pause can be useful on laptops or devices with insufficient cooling.</p> </li> </ul> <p>The <code>UNLOAD_MODELS_BEFORE_WARMUP</code> variable controls whether models are unloaded from memory before the warm-up run. By default, it is set to <code>1</code>. Setting it to <code>0</code> will skip unloading models before the warm-up.</p> <p>Warning</p> <p>Setting <code>UNLOAD_MODELS_BEFORE_WARMUP=0</code> may cause the <code>GPU Memory</code> column to be inaccurate, as models from previous flows could remain loaded in memory.</p>"},{"location":"how_to_benchmark/#conclusion","title":"Conclusion","text":"<p>By following the steps outlined above, you can successfully benchmark your Visionatrix setup. Adjust the environment variables as needed to suit your specific hardware and network conditions. If you encounter any issues or have results you'd like to share, feel free to contribute to the documentation by opening a pull request.</p> <p>Happy benchmarking!</p>"},{"location":"AdminManual/command_line_options/","title":"Command Line Options","text":"<p>Visionatrix supports various command-line options, including most of the options provided by <code>ComfyUI</code>. You can specify these options when starting Visionatrix manually.</p> <p>For example:</p> <pre><code>python3 -m visionatrix --verbose=WARNING run --ui --disable-smart-memory\n</code></pre> <p>Below are the command-line options related to Visionatrix and ComfyUI.</p>"},{"location":"AdminManual/command_line_options/#common-options-for-multiple-commands","title":"Common Options for Multiple Commands","text":"<p>The following option can be specified for the <code>install</code>, <code>update</code>, <code>install-flow</code>, <code>orphan-models</code>, and <code>openapi</code> commands:</p> <ul> <li><code>--comfy_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#the-run-command","title":"The <code>run</code> Command","text":"<p>Starts the Visionatrix.</p>"},{"location":"AdminManual/command_line_options/#syntax","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] run [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options","title":"Options","text":""},{"location":"AdminManual/command_line_options/#visionatrix-specific-options","title":"Visionatrix-Specific Options","text":"<ul> <li> <p><code>--host=HOST</code>: Host to listen on (DEFAULT or SERVER mode).</p> <p>Info</p> <p>This corresponds to ComfyUI's <code>--listen</code> argument.</p> </li> <li> <p><code>--port=PORT</code>: Port to listen on (DEFAULT or SERVER mode).</p> </li> <li><code>--server=SERVER_ADDRESS</code>: Address of Vix Server (WORKER mode).</li> <li> <p><code>--mode {DEFAULT,WORKER,SERVER}</code>: Visionatrix operating mode.</p> <p>Choices: DEFAULT, WORKER, SERVER</p> </li> <li> <p><code>--ui [UI_DIR]</code>: Enable WebUI (DEFAULT or SERVER mode).</p> <ul> <li>If <code>--ui</code> is provided without a value, the default UI is enabled.</li> <li>If <code>--ui</code> is provided with a directory, it specifies the UI directory.</li> </ul> </li> <li><code>--tasks_files_dir=FILES_DIR</code>: Directory for input/output files. Default: <code>vix_task_files</code></li> <li><code>--disable-device-detection</code>: Disable automatic device detection.</li> <li> <p><code>--verbose [LEVEL]</code>: Set the logging level.</p> <p>Choices: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>.</p> <p>Default: <code>INFO</code> or the value of the <code>LOG_LEVEL</code> environment variable.</p> <p>Note</p> <p>Note: The <code>--verbose</code> option should be specified before any command (e.g., <code>run</code>, <code>install</code>, <code>update</code>).</p> </li> <li> <p><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></p> </li> </ul>"},{"location":"AdminManual/command_line_options/#comfyui-options","title":"ComfyUI Options","text":"<p>Visionatrix supports most of ComfyUI's command-line options for the <code>run</code> command. You can pass ComfyUI options when starting Visionatrix, and they will be forwarded to ComfyUI.</p> <p>Note: The following ComfyUI options are not supported in Visionatrix:</p> <ul> <li><code>--tls-keyfile</code></li> <li><code>--tls-certfile</code></li> <li><code>--enable-cors-header</code></li> <li><code>--verbose</code> (Visionatrix uses its own <code>--verbose</code> option)</li> <li><code>--dont-print-server</code></li> <li><code>--quick-test-for-ci</code></li> <li><code>--windows-standalone-build</code></li> <li><code>--auto-launch</code></li> <li><code>--disable-auto-launch</code></li> <li><code>--multi-user</code> (Visionatrix always supports multiple users)</li> </ul> <p>All other ComfyUI options can be used. Below is a list of supported ComfyUI options:</p>"},{"location":"AdminManual/command_line_options/#device-and-performance-options","title":"Device and Performance Options","text":"<ul> <li><code>--cuda-device DEVICE_ID</code>: Set the ID of the CUDA device this instance will use.</li> <li><code>--cuda-malloc</code>: Enable cudaMallocAsync (enabled by default for PyTorch 2.0 and up).</li> <li><code>--disable-cuda-malloc</code>: Disable cudaMallocAsync.</li> <li><code>--force-fp32</code>: Force fp32 precision (If this makes your GPU work better, please report it).</li> <li><code>--force-fp16</code>: Force fp16 precision.</li> </ul>"},{"location":"AdminManual/command_line_options/#unet-precision-options","title":"UNET Precision Options","text":"<ul> <li><code>--bf16-unet</code>: Run the UNET in bf16 precision. This should only be used for testing purposes.</li> <li><code>--fp16-unet</code>: Store UNET weights in fp16 precision.</li> <li><code>--fp8_e4m3fn-unet</code>: Store UNET weights in fp8_e4m3fn format.</li> <li><code>--fp8_e5m2-unet</code>: Store UNET weights in fp8_e5m2 format.</li> </ul>"},{"location":"AdminManual/command_line_options/#vae-precision-options","title":"VAE Precision Options","text":"<ul> <li><code>--fp16-vae</code>: Run the VAE in fp16 precision (might cause black images).</li> <li><code>--fp32-vae</code>: Run the VAE in full precision fp32.</li> <li><code>--bf16-vae</code>: Run the VAE in bf16 precision.</li> <li><code>--cpu-vae</code>: Run the VAE on the CPU.</li> </ul>"},{"location":"AdminManual/command_line_options/#text-encoder-precision-options","title":"Text Encoder Precision Options","text":"<ul> <li><code>--fp8_e4m3fn-text-enc</code>: Store text encoder weights in fp8 (e4m3fn variant).</li> <li><code>--fp8_e5m2-text-enc</code>: Store text encoder weights in fp8 (e5m2 variant).</li> <li><code>--fp16-text-enc</code>: Store text encoder weights in fp16.</li> <li><code>--fp32-text-enc</code>: Store text encoder weights in fp32.</li> </ul>"},{"location":"AdminManual/command_line_options/#other-performance-options","title":"Other Performance Options","text":"<ul> <li><code>--force-channels-last</code>: Force channels-last format when inferring the models.</li> <li><code>--disable-ipex-optimize</code>: Disable <code>ipex.optimize</code> when loading models with Intel GPUs.</li> </ul>"},{"location":"AdminManual/command_line_options/#caching-options","title":"Caching Options","text":"<ul> <li><code>--cache-classic</code>: Use the old style (aggressive) caching.</li> <li><code>--cache-lru N</code>: Use LRU caching with a maximum of N node results cached. May use more RAM/VRAM.</li> </ul>"},{"location":"AdminManual/command_line_options/#attention-optimization-options","title":"Attention Optimization Options","text":"<ul> <li><code>--use-split-cross-attention</code>: Use the split cross-attention optimization. Ignored when xformers is used.</li> <li><code>--use-quad-cross-attention</code>: Use the sub-quadratic cross-attention optimization. Ignored when xformers is used.</li> <li><code>--use-pytorch-cross-attention</code>: Use the new PyTorch 2.0 cross-attention function.</li> <li><code>--disable-xformers</code>: Disable xformers.</li> <li><code>--force-upcast-attention</code>: Force enable attention upcasting (please report if it fixes black images).</li> <li><code>--dont-upcast-attention</code>: Disable all upcasting of attention. Should be unnecessary except for debugging.</li> </ul>"},{"location":"AdminManual/command_line_options/#memory-and-device-options","title":"Memory and Device Options","text":"<ul> <li><code>--gpu-only</code>: Store and run everything (text encoders/CLIP models, etc.) on the GPU.</li> <li><code>--highvram</code>: Keep models in GPU memory instead of unloading to CPU memory after use.</li> <li><code>--normalvram</code>: Force normal VRAM usage if low VRAM gets automatically enabled.</li> <li><code>--lowvram</code>: Split the UNET into parts to use less VRAM.</li> <li><code>--novram</code>: Use when <code>--lowvram</code> isn't enough.</li> <li><code>--cpu</code>: Use the CPU for everything (slow).</li> <li><code>--reserve-vram VRAM_GB</code>: Set the amount of VRAM in GB you want to reserve for use by your OS/other software.</li> <li><code>--disable-smart-memory</code>: Force ComfyUI to aggressively offload to regular RAM instead of keeping models in VRAM when it can.</li> </ul>"},{"location":"AdminManual/command_line_options/#other-options","title":"Other Options","text":"<ul> <li><code>--fast</code>: Enable some untested and potentially quality-deteriorating optimizations.</li> </ul>"},{"location":"AdminManual/command_line_options/#examples","title":"Examples","text":""},{"location":"AdminManual/command_line_options/#running-visionatrix-with-specific-gpu-settings","title":"Running Visionatrix with Specific GPU Settings","text":"<p>To run Visionatrix using the first CUDA device and enable split cross-attention optimization:</p> <pre><code>python3 -m visionatrix run --cuda-device 0 --use-split-cross-attention\n</code></pre>"},{"location":"AdminManual/command_line_options/#running-in-worker-mode","title":"Running in WORKER Mode","text":"<p>To run Visionatrix in WORKER mode, connecting to a Vix Server:</p> <pre><code>python3 -m visionatrix run --mode WORKER --server http://your_vix_server_address\n</code></pre>"},{"location":"AdminManual/command_line_options/#enabling-the-web-ui","title":"Enabling the Web UI","text":"<p>To start Visionatrix with the default Web UI:</p> <pre><code>python3 -m visionatrix run --ui\n</code></pre> <p>To specify a custom UI directory:</p> <pre><code>python3 -m visionatrix run --ui /path/to/your/ui_directory\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-install-command","title":"The <code>install</code> Command","text":"<p>Performs cleanup and initialization.</p>"},{"location":"AdminManual/command_line_options/#syntax_1","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] install [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_1","title":"Options","text":"<ul> <li><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#example","title":"Example","text":"<pre><code>python3 -m visionatrix install\n</code></pre> <p>During installation, you will be prompted to confirm whether to clear flows and ComfyUI folder.</p>"},{"location":"AdminManual/command_line_options/#the-update-command","title":"The <code>update</code> Command","text":"<p>Performs an update to the latest version.</p>"},{"location":"AdminManual/command_line_options/#syntax_2","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] update [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_2","title":"Options","text":"<ul> <li><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#example_1","title":"Example","text":"<pre><code>python3 -m visionatrix update\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-install-flow-command","title":"The <code>install-flow</code> Command","text":"<p>Installs a flow by name, tag, or from a file. Useful for workers that do not have a user interface.</p>"},{"location":"AdminManual/command_line_options/#syntax_3","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] install-flow [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_3","title":"Options","text":"<p>You must specify one of the following options:</p> <ul> <li><code>--file=FILE_PATH</code>: Path to <code>comfyui_flow.json</code> file or a directory containing flow files.</li> <li>The file should contain a ComfyUI workflow with the metadata needed for Visionatrix.</li> <li><code>--name=FLOW_NAME</code>: Flow name mask of the flow(s).</li> <li>This will install the flow by its <code>ID</code>, which is equal to its folder name here.</li> <li><code>--tag=TAG</code>: Flow tags mask of the flow(s).</li> </ul> <p>Additional options:</p> <ul> <li><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#examples_1","title":"Examples","text":""},{"location":"AdminManual/command_line_options/#installing-from-a-file","title":"Installing from a File","text":"<pre><code>python3 -m visionatrix install-flow --file=path_to_comfyui_flow.json\n</code></pre> <p>The file should contain a ComfyUI workflow with the metadata needed for Visionatrix.</p>"},{"location":"AdminManual/command_line_options/#installing-by-name","title":"Installing by Name","text":"<pre><code>python3 -m visionatrix install-flow --name=photo_stickers\n</code></pre> <p>This will install the flow by its <code>ID</code>, which is equal to its folder name here.</p>"},{"location":"AdminManual/command_line_options/#installing-by-tag","title":"Installing by Tag","text":"<pre><code>python3 -m visionatrix install-flow --tag=your_tag\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-create-user-command","title":"The <code>create-user</code> Command","text":"<p>Creates a new user.</p>"},{"location":"AdminManual/command_line_options/#syntax_4","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] create-user [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_4","title":"Options","text":"<ul> <li><code>--name=USERNAME</code> (required): User name (ID).</li> <li><code>--password=PASSWORD</code> (required): User password.</li> <li><code>--full_name=FULL_NAME</code>: Full user name. Default: <code>John Doe</code>.</li> <li><code>--email=EMAIL</code>: User's email address. Default: <code>user@example.com</code>.</li> <li><code>--admin=BOOLEAN</code>: Should the user be an admin. Default: <code>True</code>.</li> <li><code>--disabled=BOOLEAN</code>: Should the account be disabled. Default: <code>False</code>.</li> </ul>"},{"location":"AdminManual/command_line_options/#example_2","title":"Example","text":"<pre><code>python3 -m visionatrix create-user --name=username --password=userpassword --email=user@example.com\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-orphan-models-command","title":"The <code>orphan-models</code> Command","text":"<p>Removes orphan models.</p>"},{"location":"AdminManual/command_line_options/#syntax_5","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] orphan-models [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_5","title":"Options","text":"<ul> <li><code>--no-confirm</code>: Do not ask for confirmation for each model.</li> <li><code>--dry-run</code>: Perform cleaning without actually removing models.</li> <li><code>--include-useful-models</code>: Include orphaned models that can be used in future flows for removal.</li> <li><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#example_3","title":"Example","text":"<pre><code>python3 -m visionatrix orphan-models --no-confirm --dry-run\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-openapi-command","title":"The <code>openapi</code> Command","text":"<p>Generates OpenAPI specifications.</p>"},{"location":"AdminManual/command_line_options/#syntax_6","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] openapi [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_6","title":"Options","text":"<ul> <li><code>--file=FILENAME</code>: Filename to save. Default: <code>openapi.json</code>.</li> <li><code>--indentation=SIZE</code>: Indentation size. Default: <code>2</code>.</li> <li><code>--flows=FLOWS</code>: Flows to include in OpenAPI specs (comma-separated list or <code>*</code>).<ul> <li>If <code>--flows</code> is <code>*</code>, include all endpoints and all installed flows.</li> <li>If <code>--flows</code> is specified but empty (e.g., <code>--flows=\"\"</code>), do not include any flows.</li> <li>If <code>--flows</code> is a comma-separated list of flow names (e.g., <code>--flows=flow1,flow2</code>), include those flows.</li> </ul> </li> <li><code>--skip-not-installed</code>: Skip flows that are not installed. Default: <code>True</code>.</li> <li><code>--exclude-base</code>: Exclude base application endpoints from OpenAPI specs.</li> <li><code>--comfyui_dir=COMFYUI_DIR</code>: Directory for the folder with ComfyUI. Default: <code>ComfyUI</code></li> </ul>"},{"location":"AdminManual/command_line_options/#examples_2","title":"Examples","text":""},{"location":"AdminManual/command_line_options/#generate-openapi-specs-for-all-endpoints-and-all-installed-flows","title":"Generate OpenAPI Specs for All Endpoints and All Installed Flows","text":"<pre><code>python3 -m visionatrix openapi --flows=\"*\" --file=my_openapi.json\n</code></pre>"},{"location":"AdminManual/command_line_options/#generate-openapi-specs-for-specific-flows-only","title":"Generate OpenAPI Specs for Specific Flows Only","text":"<pre><code>python3 -m visionatrix openapi --flows=flow1,flow2 --exclude-base --file=my_openapi.json\n</code></pre>"},{"location":"AdminManual/command_line_options/#generate-openapi-specs-without-any-flows","title":"Generate OpenAPI Specs Without Any Flows","text":"<pre><code>python3 -m visionatrix openapi --file=my_openapi.json\n</code></pre>"},{"location":"AdminManual/environment_variables/","title":"Environment Variables","text":"<p>In addition to the usual ways of setting environment variables, they can be set via a <code>.env</code> file. Visionatrix uses the python-dotenv package to load variables from a <code>.env</code> file.</p> <p>Additionally, some variables can also be specified via command-line arguments, which take precedence over environment variables.</p> <p>This document describes the available environment variables, their default values, and how they affect Visionatrix's operation.</p>"},{"location":"AdminManual/environment_variables/#using-a-env-file","title":"Using a <code>.env</code> File","text":"<p>To simplify configuration, you can create a <code>.env</code> file in the root directory of your Visionatrix installation. In this file, you can define environment variables in the format:</p> <pre><code>VARIABLE_NAME=value\n</code></pre>"},{"location":"AdminManual/environment_variables/#general-variables","title":"General Variables","text":""},{"location":"AdminManual/environment_variables/#comfyui_dir","title":"COMFYUI_DIR","text":"<ul> <li>Description: Directory for the folder containing ComfyUI. The path can be absolute or relative.</li> <li> <p>Default: <code>./ComfyUI</code></p> <p>Note</p> <p>The command-line argument <code>--comfyui_dir=COMFYUI_DIR</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#tasks_files_dir","title":"TASKS_FILES_DIR","text":"<ul> <li>Description: Directory for input/output files. The path can be absolute or relative.</li> <li> <p>Default: Absolute path to <code>./vix_tasks_files</code></p> <p>Note</p> <p>The command-line argument <code>--tasks_files_dir=FILES_DIR</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#ui_dir","title":"UI_DIR","text":"<ul> <li>Description: Path to the User Interface (JavaScript frontend). This is the directory that will be served as the root of the website.</li> <li> <p>Default: Empty string.</p> <p>Note</p> <ul> <li>Command-line Argument:</li> <li><code>--ui</code> (enables the User Interface using the default frontend), or</li> <li><code>--ui=/path/to/frontend</code> (specifies the path to a custom frontend).</li> </ul> <p>Command-line arguments take precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_mode","title":"VIX_MODE","text":"<ul> <li>Description: Determines the working mode of Visionatrix.</li> <li> <p><code>DEFAULT</code>: Storage and delivery of tasks (Server) + task processing (Worker).</p> <p>Note</p> <p>Authentication is disabled in this mode.</p> </li> <li> <p><code>SERVER</code>: Only storage and management of tasks.</p> <p>Note</p> <p>Authentication is enabled. Requires a PostgreSQL database.</p> </li> <li> <p><code>WORKER</code>: Only processes tasks from the Server (client consuming mode, no backend).</p> </li> <li> <p>Default: <code>DEFAULT</code></p> <p>Note</p> <p>The command-line argument <code>--mode=</code> takes precedence over the environment variable.</p> </li> </ul> <p>Please refer to the Working Modes documentation for more details.</p>"},{"location":"AdminManual/environment_variables/#variables-for-specific-modes","title":"Variables for Specific Modes","text":""},{"location":"AdminManual/environment_variables/#server-and-default-mode","title":"SERVER and DEFAULT Mode","text":""},{"location":"AdminManual/environment_variables/#vix_host","title":"VIX_HOST","text":"<ul> <li>Description: Address to bind to in the <code>DEFAULT</code> or <code>SERVER</code> mode.</li> <li> <p>Default: <code>127.0.0.1</code> (binds to the local interface)</p> <p>Note</p> <p>The command-line argument <code>--host=HOST</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_port","title":"VIX_PORT","text":"<ul> <li>Description: Port to bind to in the <code>DEFAULT</code> or <code>SERVER</code> mode.</li> <li> <p>Default: <code>8288</code></p> <p>Note</p> <p>The command-line argument <code>--port=PORT</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_server_workers","title":"VIX_SERVER_WORKERS","text":"<ul> <li>Description: Number of server instances to spawn (using Uvicorn). Useful for production environments with a large number of users.</li> <li>Default: <code>1</code></li> </ul>"},{"location":"AdminManual/environment_variables/#vix_server_full_models","title":"VIX_SERVER_FULL_MODELS","text":"<ul> <li>Description: Flag that determines whether full models rather than dummy models should be stored in <code>SERVER</code> mode. Useful when both the Server and Workers are on the same machine, or when the <code>MODELS_DIR</code> is shared between the Server and Workers.</li> <li>Default: <code>0</code> (disabled)</li> <li>Set to: <code>1</code> to enable.</li> </ul>"},{"location":"AdminManual/environment_variables/#database_uri","title":"DATABASE_URI","text":"<ul> <li> <p>Description: URI for the database used by Visionatrix. Required in <code>SERVER</code> mode.</p> <p>Warning</p> <p>SQLite is not supported in the <code>SERVER</code> mode.</p> </li> <li> <p>Default: <code>sqlite:///./tasks_history.db</code></p> </li> <li>For SQLite: If the path is relative, it is relative to the current directory.</li> <li>Note: For PostgreSQL, the format is: <code>postgresql+psycopg://user:password@host:port/database</code></li> </ul>"},{"location":"AdminManual/environment_variables/#worker-mode","title":"WORKER Mode","text":"<p>When running in <code>WORKER</code> mode, the following variables are relevant:</p>"},{"location":"AdminManual/environment_variables/#vix_server","title":"VIX_SERVER","text":"<ul> <li>Description: The full URL of the Server to connect to when running in <code>WORKER</code> mode in the Worker to Server configuration.</li> <li> <p>Default: Empty string (must be set in <code>WORKER</code> mode if not using <code>DATABASE_URI</code>)</p> <p>Warning</p> <p>If <code>VIX_SERVER</code> is set, the Worker will communicate with the Server via the network; <code>DATABASE_URI</code> will be ignored.</p> <p>You are required to specify either <code>VIX_SERVER</code> or <code>DATABASE_URI</code> for the Worker, so it can fetch tasks to process.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#database_uri_1","title":"DATABASE_URI","text":"<ul> <li>Description: In <code>WORKER</code> mode, it is used only for the Worker to Database-FS configuration.</li> <li>Default: <code>sqlite:///./tasks_history.db</code></li> <li>Note: For Workers connecting directly to a PostgreSQL database, use the appropriate <code>DATABASE_URI</code>.</li> </ul>"},{"location":"AdminManual/environment_variables/#worker_auth","title":"WORKER_AUTH","text":"<ul> <li>Description: Authentication credentials for the Worker when connecting to the Server. Format: <code>USER_ID:PASSWORD</code></li> <li> <p>Default: <code>admin:admin</code></p> <p>Note</p> <p>This is only applicable for the Worker to Server configuration.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#worker_net_timeout","title":"WORKER_NET_TIMEOUT","text":"<ul> <li>Description: Network timeout in seconds for the Worker when communicating with the Server.</li> <li> <p>Default: <code>15.0</code></p> <p>Note</p> <p>This is only applicable for the Worker to Server configuration.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#other-variables","title":"Other Variables","text":""},{"location":"AdminManual/environment_variables/#flows_url","title":"FLOWS_URL","text":"<ul> <li>Description: URLs or file paths (separated by semicolons <code>;</code>) that point to locations of archive files containing lists and definitions of Visionatrix workflows. Specifies where Visionatrix fetches the available flows.</li> <li>Default: <code>https://visionatrix.github.io/VixFlowsDocs/</code></li> <li>More Information: Workflows Storage</li> </ul>"},{"location":"AdminManual/environment_variables/#models_catalog_url","title":"MODELS_CATALOG_URL","text":"<ul> <li>Description: URL or file path to fetch the models catalog for ComfyUI workflows. This catalog specifies available models.</li> <li>Default: <code>https://visionatrix.github.io/VixFlowsDocs/models_catalog.json</code></li> </ul>"},{"location":"AdminManual/environment_variables/#min_pause_interval","title":"MIN_PAUSE_INTERVAL","text":"<ul> <li>Description: Minimum interval in seconds (float) that the Worker waits between checking for new tasks when none are available. Helps reduce server load when idle.</li> <li>Default: <code>0.1</code></li> </ul>"},{"location":"AdminManual/environment_variables/#max_pause_interval","title":"MAX_PAUSE_INTERVAL","text":"<ul> <li>Description: Maximum interval in seconds (float) that the Worker waits between checking for new tasks when none are available. The pause interval increases gradually from <code>MIN_PAUSE_INTERVAL</code> to <code>MAX_PAUSE_INTERVAL</code> in 10 steps.</li> <li>Default: <code>1.0</code></li> </ul>"},{"location":"AdminManual/environment_variables/#gc_collect_interval","title":"GC_COLLECT_INTERVAL","text":"<ul> <li>Description: Interval in seconds (float) after which the GPU memory release and garbage collection procedure is called after task execution. Not recommended to change unless you know what you're doing.</li> <li>Default: <code>10.0</code></li> </ul>"},{"location":"AdminManual/environment_variables/#user_backends","title":"USER_BACKENDS","text":"<ul> <li>Description: List of user backends to enable. Each backend supports its own environment variables for configuration.</li> <li>Default: <code>vix_db</code></li> <li>Format: Semicolon-separated list of backends (e.g., <code>vix_db;nextcloud</code>)</li> <li>Example:   <pre><code>USER_BACKENDS=vix_db;nextcloud\n</code></pre>   This will enable the <code>nextcloud</code> user backend in addition to the default <code>vix_db</code>.</li> </ul>"},{"location":"AdminManual/environment_variables/#max_parallel_downloads","title":"MAX_PARALLEL_DOWNLOADS","text":"<ul> <li>Description: Maximum number of parallel downloads allowed during workflow installation.</li> <li>Default: <code>2</code></li> </ul>"},{"location":"AdminManual/environment_variables/#max_git_clone_attempts","title":"MAX_GIT_CLONE_ATTEMPTS","text":"<ul> <li>Description: Maximum number of attempts to perform <code>git clone</code> operations during installation or updates.</li> <li>Default: <code>3</code></li> </ul>"},{"location":"AdminManual/environment_variables/#cors_origins","title":"CORS_ORIGINS","text":"<ul> <li>Description: A comma-separated list of origins that are allowed to make Cross-Origin Resource Sharing (CORS) requests to the server. This is necessary when the frontend and backend are hosted on different domains or ports. By specifying allowed origins, you enable frontend applications running on those origins to interact with the Visionatrix backend.</li> <li>Default: Empty string (CORS is disabled; only same-origin requests are allowed).</li> <li> <p>Example:</p> <pre><code>CORS_ORIGINS=\"http://localhost:3000,http://192.168.1.132:3000,http://192.168.1.132:8288\"\n</code></pre> <p>In this example, requests are permitted from:</p> <ul> <li><code>http://localhost:3000</code></li> <li><code>http://192.168.1.132:3000</code></li> <li><code>http://192.168.1.132:8288</code></li> </ul> <p>Note</p> <p>This setting is important when developing or deploying the frontend separately from the backend, especially during development when the frontend might be served by a development server on a different port.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#examples","title":"Examples","text":""},{"location":"AdminManual/environment_variables/#using-a-env-file_1","title":"Using a <code>.env</code> File","text":"<p>Create a file named <code>.env</code> in the root directory of Visionatrix with the following content:</p> <pre><code># Set the working mode to SERVER\nVIX_MODE=SERVER\n\n# Set the database URI to use PostgreSQL\nDATABASE_URI=postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\n\n# Set the number of server workers\nVIX_SERVER_WORKERS=4\n\n# Enable full models on the server\nVIX_SERVER_FULL_MODELS=1\n\n# Specify the host and port to bind to\nVIX_HOST=0.0.0.0\nVIX_PORT=8000\n</code></pre>"},{"location":"AdminManual/environment_variables/#setting-variables-in-the-environment","title":"Setting Variables in the Environment","text":"<p>On Linux or macOS:</p> <pre><code>export VIX_MODE=WORKER\nexport VIX_SERVER=http://server_address:8000\nexport WORKER_AUTH=worker_user:worker_password\n</code></pre> <p>On Windows Command Prompt:</p> <pre><code>set VIX_MODE=WORKER\nset VIX_SERVER=http://server_address:8000\nset WORKER_AUTH=worker_user:worker_password\n</code></pre>"},{"location":"AdminManual/environment_variables/#starting-visionatrix-with-command-line-arguments","title":"Starting Visionatrix with Command-Line Arguments","text":"<pre><code>python3 -m visionatrix run --comfyui_dir=/path/to/comfyui --tasks_files_dir=/path/to/tasks_files --ui\n</code></pre> <p>In this example, the directories are specified via command-line arguments, which will override any environment variables or settings in the <code>.env</code> file.</p>"},{"location":"AdminManual/Installation/installation/","title":"Installation","text":"<p>In most cases, we recommend using automatic installation via an <code>easy-install</code> script.</p> <p>Download and execute <code>easy_install.py</code> script:</p> <p>Note</p> <p>It will clone this repository into the current folder and perform the installation.</p> <p>After installation you can always run <code>easy_install</code> from the \"scripts\" folder.</p> <p>With wget: <pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; python3 easy_install.py\n</code></pre></p> <p>or with curl: <pre><code>curl -o easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; python3 easy_install.py\n</code></pre></p>"},{"location":"AdminManual/Installation/installation/#manual-installation","title":"Manual Installation","text":"<p>For those who want to install everything manually, here you will find step-by-step instructions on what the script does.</p>"},{"location":"AdminManual/Installation/installation/#virtual-environment-creation","title":"Virtual Environment creation","text":"<p>First clone the repository with <code>git</code>:</p> <pre><code>git clone https://github.com/Visionatrix/Visionatrix.git &amp;&amp; cd Visionatrix\n</code></pre> <p>Setup the virtual environment with <code>python</code>:</p> <pre><code>python -m venv venv\n</code></pre> <p>Activate Virtual Environment(Linux/macOS) with <code>source</code>:</p> <pre><code>source venv/bin/activate\n</code></pre> <p>Activate Virtual Environment(Windows) with <code>powershell</code>:</p> <pre><code>.\\venv\\Scripts\\Activate.ps1\n</code></pre>"},{"location":"AdminManual/Installation/installation/#pytorch-installation","title":"PyTorch installation","text":"<p>Note</p> <p>On macOS currently no action is needed.</p> <p>For AMD graphic cards on Linux install ROCM version of PyTorch using <code>pip</code>:</p> <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1\n</code></pre> <p>For AMD graphics cards on Windows install PyTorch with DirectML support using <code>pip</code>:</p> <pre><code>pip install torch-directml\n</code></pre> <p>Python3.10 is the only currently supported version by torch-directml.</p> <p>For NVIDIA graphics cards on Linux install PyTorch with next <code>pip</code> command:</p> <pre><code>pip install torch torchvision torchaudio\n</code></pre> <p>For NVIDIA graphics cards on Windows install PyTorch using <code>pip</code> specifying PyTorch and CUDA version:</p> <pre><code>pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n</code></pre>"},{"location":"AdminManual/Installation/installation/#install-visionatrix","title":"Install Visionatrix","text":"<p>Install Visionatrix from the previously cloned sources using <code>pip</code>:</p> <pre><code>pip install .\n</code></pre> <p>Run Visionatrix initialization command using <code>python</code>:</p> <pre><code>python -m visionatrix install\n</code></pre>"},{"location":"AdminManual/Installation/installation/#run-visionatrix","title":"Run Visionatrix","text":"<p>Execute from the activated virtual environment run command using <code>python</code>:</p> <pre><code>python -m visionatrix run --ui\n</code></pre>"},{"location":"AdminManual/Installation/installation/#update-process","title":"Update process","text":""},{"location":"AdminManual/Installation/installation/#recommended-way","title":"Recommended way","text":"<p>Note</p> <p>On Windows this method currently does not supported.</p> <p>With the <code>easy_install.py</code> script:</p> <pre><code>python3 scripts/easy_install.py\n</code></pre> <p>and select option Update (2)</p>"},{"location":"AdminManual/Installation/installation/#manual-update","title":"Manual Update","text":"<p>Note</p> <p>On Windows this method requires installed git and Visual Studio Compilers</p> <ol> <li> <p>Pull last changes from repository with <code>git</code>:</p> <pre><code>git pull\n</code></pre> </li> <li> <p>Execute update command from activated virtual environment with <code>python</code>:</p> <pre><code>python -m visionatrix update\n</code></pre> </li> </ol>"},{"location":"AdminManual/Installation/installation/#update-algorithm","title":"Update algorithm","text":"<p>Development versions are updated only to development versions, release versions only to release ones.</p> <p>Note</p> <p>If you are not a developer, you are better off using the release version, as they should be more stable.</p> <p>The update scheme in easy_install.py is quite simple; everything is done with ordinary Git commands.</p> <ul> <li> <p>If the current version is a dev release or the current branch is     <code>main</code> then:</p> <ol> <li>Check out the <code>main</code> branch.</li> <li>Pull the latest changes from the remote repository.</li> </ol> </li> <li> <p>If the current version is a tagged release version:</p> <ol> <li>Determine the latest tag for the current major version, and if     a newer version tag is found, check out the latest version tag     within the current major version.</li> <li>If no newer version is found within the current major version,     check for the next major version.</li> <li>If a newer major version tag is found, prompt the user to     update to this newer major version.</li> </ol> </li> <li> <p>After checking out the appropriate version, executes a <code>pip install</code>     command to update the Python packages.</p> </li> <li> <p>Finally, executes the <code>python3 -m visionatrix update</code> command to ensure     that any additional necessary updates are applied (ComfyUI, custom nodes, flows).</p> </li> </ul>"},{"location":"AdminManual/Installation/pgsql/","title":"How to Install PostgreSQL","text":"<p>This guide provides step-by-step instructions on how to install PostgreSQL on Linux, macOS, and Windows systems.</p> <p>This is recommended only for Visionatrix running in SERVER mode.</p>"},{"location":"AdminManual/Installation/pgsql/#installation-on-linux","title":"Installation on Linux","text":""},{"location":"AdminManual/Installation/pgsql/#installing-on-ubuntudebian","title":"Installing on Ubuntu/Debian","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-update-package-lists","title":"Step 1: Update Package Lists","text":"<p>Open a terminal and update your package lists:</p> <pre><code>sudo apt update\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-install-postgresql","title":"Step 2: Install PostgreSQL","text":"<p>Install PostgreSQL along with the <code>postgresql-contrib</code> package, which provides additional utilities and features:</p> <pre><code>sudo DEBIAN_FRONTEND=noninteractive apt install -y postgresql postgresql-contrib\n</code></pre> <p>Note: This command will install the default version of PostgreSQL available in your distribution's repositories.</p>"},{"location":"AdminManual/Installation/pgsql/#step-3-start-postgresql","title":"Step 3: Start PostgreSQL","text":"<p>Start the PostgreSQL service:</p> <pre><code>sudo systemctl start postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installing-on-centosrhel","title":"Installing on CentOS/RHEL","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-add-repository","title":"Step 1: Add Repository","text":"<p>Enable the PostgreSQL repository for the desired version.</p> <p>Replace <code>13</code> with your preferred version (<code>12</code>, <code>13</code>, <code>14</code>, etc.):</p> <pre><code>sudo yum install -y https://download.postgresql.org/pub/repos/yum/13/redhat/rhel-$(rpm -E %{rhel})-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n</code></pre> <p>Note: Where you see <code>postgresql13</code>, it can be <code>postgresql12</code> or <code>postgresql14</code> based on the version you want.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-disable-the-default-postgresql-module","title":"Step 2: Disable the Default PostgreSQL Module","text":"<p>For CentOS/RHEL 8 and newer:</p> <pre><code>sudo dnf -qy module disable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-install-postgresql","title":"Step 3: Install PostgreSQL","text":"<p>Install PostgreSQL server:</p> <pre><code>sudo yum install -y postgresql13-server\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-initialize-and-enable","title":"Step 4: Initialize and Enable","text":"<p>Initialize the database and enable automatic start:</p> <pre><code>sudo /usr/pgsql-13/bin/postgresql-13-setup initdb\nsudo systemctl enable postgresql-13\nsudo systemctl start postgresql-13\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installing-on-fedora","title":"Installing on Fedora","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-install-postgresql","title":"Step 1: Install PostgreSQL","text":"<p>Install PostgreSQL server and contrib packages:</p> <pre><code>sudo dnf install postgresql-server postgresql-contrib\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-initialize-database","title":"Step 2: Initialize Database","text":"<p>Initialize the PostgreSQL database:</p> <pre><code>sudo postgresql-setup --initdb\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-start-postgresql_1","title":"Step 3: Start PostgreSQL","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installation-on-macos","title":"Installation on macOS","text":""},{"location":"AdminManual/Installation/pgsql/#using-homebrew","title":"Using Homebrew","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-install-homebrew","title":"Step 1: Install Homebrew","text":"<p>If you don't have Homebrew installed, run:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-update-homebrew","title":"Step 2: Update Homebrew","text":"<pre><code>brew update\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-install-postgresql_1","title":"Step 3: Install PostgreSQL","text":"<pre><code>brew install postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-start-postgresql","title":"Step 4: Start PostgreSQL","text":"<p>To start PostgreSQL now and restart at login:</p> <pre><code>brew services start postgresql\n</code></pre> <p>Or, to run it manually:</p> <pre><code>pg_ctl -D /usr/local/var/postgres start\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#using-postgresql-installer","title":"Using PostgreSQL Installer","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-download-the-installer","title":"Step 1: Download the Installer","text":"<p>Download the PostgreSQL installer for macOS from the official PostgreSQL website.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-run-the-installer","title":"Step 2: Run the Installer","text":"<ul> <li>Open the downloaded <code>.dmg</code> file.</li> <li>Run the installer and follow the on-screen instructions.</li> <li>Set a password for the <code>postgres</code> user when prompted.</li> </ul>"},{"location":"AdminManual/Installation/pgsql/#installation-on-windows","title":"Installation on Windows","text":""},{"location":"AdminManual/Installation/pgsql/#postgresql-installer","title":"PostgreSQL Installer","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-download-the-installer_1","title":"Step 1: Download the Installer","text":"<p>Download the PostgreSQL installer for Windows from the official PostgreSQL website.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-run-the-installer_1","title":"Step 2: Run the Installer","text":"<ul> <li>Double-click the downloaded <code>.exe</code> file.</li> <li>Follow the installation wizard steps:<ul> <li>Set a password for the PostgreSQL superuser (<code>postgres</code>).</li> <li>Choose the port number (default is 5432).</li> <li>Wait for the installation to complete.</li> </ul> </li> </ul>"},{"location":"AdminManual/Installation/pgsql/#post-installation-setup","title":"Post-Installation Setup","text":""},{"location":"AdminManual/Installation/pgsql/#initializing-the-database","title":"Initializing the Database","text":"<p>In most cases, the database is initialized during installation. If not, follow the steps below.</p>"},{"location":"AdminManual/Installation/pgsql/#on-linux","title":"On Linux","text":"<p>For versions installed via package managers:</p> <pre><code>sudo su - postgres\n</code></pre> <p>Then initialize the database(not always required):</p> <pre><code>initdb -D /var/lib/pgsql/data\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#starting-the-postgresql","title":"Starting the PostgreSQL","text":"<p>Ensure PostgreSQL is running and set to start on boot.</p>"},{"location":"AdminManual/Installation/pgsql/#on-ubuntudebian","title":"On Ubuntu/Debian","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#on-centosrhel","title":"On CentOS/RHEL","text":"<pre><code>sudo systemctl start postgresql-13\nsudo systemctl enable postgresql-13\n</code></pre> <p>Note: Replace <code>13</code> with your PostgreSQL version number.</p>"},{"location":"AdminManual/Installation/pgsql/#on-fedora","title":"On Fedora","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#on-macos-manual-start","title":"On macOS (Manual Start)","text":"<pre><code>pg_ctl -D /usr/local/var/postgres start\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#creating-a-user-and-database","title":"Creating a User and Database","text":"<p>We will create a database named <code>vix_db</code> and a user <code>vix_user</code> with password <code>vix_password</code>, as required by Visionatrix.</p>"},{"location":"AdminManual/Installation/pgsql/#option-1-via-pgsql-shell","title":"Option 1: Via PgSQL Shell","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-switch-to-postgres","title":"Step 1: Switch to <code>postgres</code>","text":"<pre><code>sudo -u postgres psql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-create-user","title":"Step 2: Create User","text":"<pre><code>CREATE USER vix_user WITH PASSWORD 'vix_password';\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-create-database","title":"Step 3: Create Database","text":"<pre><code>CREATE DATABASE vix_db OWNER vix_user;\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-grant-privileges","title":"Step 4: Grant Privileges","text":"<pre><code>GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-5-exit-shell","title":"Step 5: Exit Shell","text":"<pre><code>\\q\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#option-2-direct-commands","title":"Option 2: Direct Commands","text":"<p>You can execute all commands directly from the terminal:</p> <pre><code>sudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\"\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#configuring-visionatrix","title":"Configuring Visionatrix","text":"<p>After installing and configuring PostgreSQL, you need to set the <code>DATABASE_URI</code> environment variable for Visionatrix to connect to the PostgreSQL database.</p> <p>Set the <code>DATABASE_URI</code> as follows:</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\"\n</code></pre> <p>This tells Visionatrix to connect to the PostgreSQL database <code>vix_db</code> on <code>localhost</code> using the user <code>vix_user</code> and password <code>vix_password</code> on port <code>5432</code>.</p> <p>Make sure to export this variable or set it in your Visionatrix configuration file as per the installation instructions.</p> <p>Good luck!</p>"},{"location":"AdminManual/Installation/proxy_gemini/","title":"HTTP Proxy for Google Gemini API Access","text":"<p>This guide will help you set up an HTTP/HTTPS proxy to use the Google Gemini API.</p> <p>This is useful if you're in a region where free direct access to the Gemini API is restricted.</p> <p>Warning</p> <p>For most countries in the world you don't need this guide!</p> <p>If you use Gemini Pro model - you don't need it either, it doesn't have free access, and paid access works from everywhere and without proxy.</p> <p>Note</p> <p>The information on this page is provided for educational purposes, so that you can check what Gemini Flash is capable of before connecting the payment method to your Google account.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Virtual Private Server (VPS) or access to a machine with a public IP address.</li> <li>Basic knowledge of server administration and command-line operations.</li> <li>A valid Google API Key.</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#why-use-a-proxy","title":"Why Use a Proxy?","text":"<p>In certain regions, direct access to the Google Gemini API may be limited or unavailable. By routing your requests through a proxy server located in a supported country, you can bypass these restrictions and use the API seamlessly.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"AdminManual/Installation/proxy_gemini/#1-obtain-vps-or-access-to-machine-with-public-ip","title":"1. Obtain VPS or access to machine with Public IP","text":"<p>You'll need to set up a proxy on a server located in a country where the Google Gemini API is accessible, such as the United States or India.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#recommended-vps-providers","title":"Recommended VPS Providers","text":"<ul> <li>DigitalOcean: Offers affordable VPS options starting at <code>$4</code> per month.</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#2-set-up-a-proxy-server-using-squid","title":"2. Set Up a Proxy Server Using Squid","text":"<p>We recommend using Squid, a high-performance proxy caching server for web clients.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#install-squid-on-your-vps","title":"Install Squid on Your VPS","text":"<p>Follow this comprehensive guide to install and configure Squid:</p> <ul> <li>DigitalOcean Squid Installation Guide: How To Set Up Squid Proxy on Ubuntu 20.04</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#3-configure-visionatrix-to-use-the-proxy","title":"3. Configure Visionatrix to Use the Proxy","text":"<p>After setting up your proxy server, update Visionatrix settings to route API requests through it.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#steps-to-configure-visionatrix","title":"Steps to Configure Visionatrix","text":"<ol> <li> <p>Navigate to the Settings page.</p> </li> <li> <p>Input your valid Google API key.</p> </li> <li> <p>Enter your proxy server's connection string.</p> <p>Format Examples:</p> <ul> <li>Without authentication:</li> </ul> <pre><code>http://proxy_host:proxy_port\n</code></pre> <ul> <li>With authentication:</li> </ul> <pre><code>http://username:password@proxy_host:proxy_port\n</code></pre> <p>Example:</p> <ul> <li>If your proxy's IP is <code>203.0.113.1</code> and port is <code>3128</code>:</li> </ul> <pre><code>http://203.0.113.1:3128\n</code></pre> </li> <li> <p>Save the Settings</p> </li> </ol>"},{"location":"AdminManual/Installation/proxy_gemini/#4-alternative-access-the-gemini-api-without-a-proxy","title":"4. Alternative: Access the Gemini API Without a Proxy","text":"<p>If you have a payment card connected, you can access the Gemini API directly from almost any country in the world.</p> <ol> <li> <p>Ensure Billing Is Set Up:</p> <ul> <li>Log in to your Google Cloud Platform account.</li> <li>Verify that your billing information and credit card are properly connected.</li> </ul> </li> <li> <p>Configure Visionatrix:</p> <ul> <li>Enter your Google API Key in the designated field.</li> <li>Leave the \"Google Proxy\" field empty.</li> </ul> </li> <li> <p>You can select the Gemini Model to use in Visionatrix settings:</p> <ul> <li>Gemini Flash(default): An affordable option suitable for most users.</li> <li>Gemini Pro: Offers superior results but is not available for free.</li> </ul> </li> </ol>"},{"location":"AdminManual/WorkingModes/worker_to_database/","title":"Setup: Worker to Database-FS Mode","text":"<p>This is the simplest production setup, when everything is up and running on one server.</p> <p>Note</p> <p>We also use this setup for benchmarks.</p> <p>This guide is for Ubuntu. Adjust it to your needs for different Linux distributions.</p> <ol> <li> <p>Log in to the server: <code>ssh ...</code></p> <p>Note</p> <p>if necessary, add port forwarding: -L 127.0.0.1:8288:127.0.0.1:8288</p> </li> <li> <p>If you are logged in as the <code>root</code> user on a clean system, install <code>sudo</code>:</p> <pre><code>apt update &amp;&amp; apt install -y sudo\n</code></pre> </li> <li> <p>Install Python, Git, and essential build tools:</p> <pre><code>sudo apt update &amp;&amp; sudo apt install -y wget curl python3-venv python3-pip build-essential git\n</code></pre> <p>Note</p> <p>On some systems you need additionally to install <code>cv2</code> dependencies:</p> <pre><code>sudo apt install -y ffmpeg libsm6 libxext6\n</code></pre> </li> <li> <p>Install and start PostgreSQL:</p> <pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\nsudo systemctl status postgresql\n</code></pre> <p> For benchmark automation script <p><pre><code>sudo DEBIAN_FRONTEND=noninteractive apt install -y postgresql postgresql-contrib &amp;&amp; pg_ctlcluster 14 main start &amp;&amp; \\\n\\\nsudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\" &amp;&amp; \\\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\" &amp;&amp; \\\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre> </p> <li> <p>Create a Visionatrix DB user:</p> <pre><code>sudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\"\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre> <p>Warning</p> <p>If you encounter the following error during Visionatrix startup:</p> <p><code>password authentication failed for user \"vix_user\"</code></p> <p>   This means you need to enable password authentication for the <code>vix_user</code>. <p>Edit <code>pg_hba.conf</code> file (typically located at <code>/etc/postgresql/XX/main/pg_hba.conf</code>) by adding following:</p> <pre><code>host    all             vix_user        127.0.0.1/32            md5\n</code></pre> <p>Then, restart PostgreSQL:</p> <pre><code>sudo systemctl restart postgresql\n</code></pre> <p>or</p> <pre><code>sudo service postgresql restart\n</code></pre> <li> <p>Install Visionatrix:</p> <pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; \\\npython3 easy_install.py &amp;&amp; \\\ncd Visionatrix &amp;&amp; source venv/bin/activate &amp;&amp; \\\npip install \".[pgsql]\" &amp;&amp; \\\n\\\nUSER_PASSWORD=$(openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 16) &amp;&amp; \\\nDATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix create-user --name admin --password \"$USER_PASSWORD\" &amp;&amp; \\\necho \"User 'admin' created with password: $USER_PASSWORD\"\n</code></pre> <p> For benchmark automation script (CUDA, Dev version) <p><pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; \\\nCOMPUTE_DEVICE=NVIDIA DEV_VERSION=1 BUILD_RELEASE=1 python3 easy_install.py &amp;&amp; \\\ncd Visionatrix &amp;&amp; source venv/bin/activate &amp;&amp; \\\npip install \".[pgsql]\" &amp;&amp; \\\nAUTO_INIT_CONFIG_MODELS_DIR=\"$(pwd)/../VixModels\" python3 scripts/easy_install.py &amp;&amp; \\\n\\\nUSER_PASSWORD=$(openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 16) &amp;&amp; \\\nDATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix create-user --name admin --password \"$USER_PASSWORD\" &amp;&amp; \\\necho \"User 'admin' created with password: $USER_PASSWORD\"\n</code></pre> </p> <li> <p>Start the Visionatrix Server(from activated venv):</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\nVIX_SERVER_FULL_MODELS=1 python3 -m visionatrix run --ui --mode=SERVER &gt; server.log 2&gt;&amp;1 &amp; echo \"Server PID: $!\"\n</code></pre> </li> <li> <p>Start the Visionatrix Worker(from activated venv):</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix run --mode=WORKER &gt; worker.log 2&gt;&amp;1 &amp; echo \"Worker PID: $!\"\n</code></pre> </li>"},{"location":"AdminManual/WorkingModes/working_modes/","title":"Working modes","text":""},{"location":"AdminManual/WorkingModes/working_modes/#default","title":"DEFAULT","text":"<p>Visionatrix(Vix) consists of:</p> <ol> <li>A server component, namely, the backend <code>(in short - Server)</code></li> <li>A component responsible for processing tasks <code>(in short - Worker)</code></li> <li>TaskQueue - a database (SQLite (default), PgSQL)</li> <li>A simple and understandable User Interface</li> </ol> <p>By default, Vix launches with all components integrated (Server + Worker + UI) for quick and easy use on a single computer.</p> <p>This is DEFAULT mode, in which everything is executed within a single process.</p> <p>Easy installation, no need to configure, just launch and use.</p> <p>Note</p> <p>There is no support for multiple users or authentication in this case, as this mode uses SQLite as a database, which is limiting. But for home use in most cases this is not necessary.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#server","title":"SERVER","text":"<p>In most scenarios, including home use, you likely have more than one device capable of handling AI tasks. In such cases, it is allowed and recommended to run the server part and the AI processing part of the task separately.</p> <p>Warning</p> <p>SQLite is not supported as a database in this mode.</p> <p>Steps to run <code>Vix</code> in a Server mode:</p> <ol> <li> <p>Install both <code>psycopg</code> and <code>greenlet</code> python libraries:</p> <p><code>pip install psycopg greenlet</code></p> </li> <li> <p>Set <code>VIX_MODE</code> environment variable to <code>SERVER</code></p> </li> <li> <p>Setup PostgreSQL database and set <code>DATABASE_URI</code> environment variable to point on it.</p> <p>Note</p> <p>PgSQL example: <code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\"</code></p> </li> <li> <p>Use <code>python3 -m visionatrix create-user</code> command to create a user in the database.</p> </li> <li> <p>Connect at least one Worker to handle task processing.</p> </li> </ol> <p>We will provide a docker-compose file soon, with full server setup to deploy it in one click.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker","title":"WORKER","text":"<p>Each worker can have a different set of tasks (Flows) installed, which is useful to avoid installing a task on a worker instance that cannot handle it. A worker will only request the tasks installed for it.</p> <p>There is two worker modes, both will be described, we ourselves most use *Vix in the <code>Worker to Server</code> mode.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker-to-database-fs","title":"Worker to Database-FS","text":"<p>Note</p> <p>Requirements:</p> <ol> <li>The database used by the Server should be accessible for the worker.</li> <li>There should be the ability to map the Server's <code>vix_tasks_files</code> folder to the worker.</li> </ol> <p>Set the environment variable <code>VIX_MODE</code> to WORKER and leave <code>VIX_SERVER</code> with an empty value.</p> <p>In this scenario, the worker must be configured with the correct database path using the <code>DATABASE_URI</code> environment variable.</p> <p>The format can be viewed here: SqlAlchemy Database URLs</p> <p>By using the <code>TASKS_FILES_DIR</code> environment variable or the <code>--tasks_files_dir</code> argument, you can change the location of the <code>vix_tasks_files</code> folder.</p> <p>The worker must have access to the Server's <code>vix_tasks_files</code> folder.</p> <p>With this scaling method, workers independently retrieve tasks from the database and directly write the execution results to the servers TASKS_FILES_DIR.</p> <p>In this setup, you can imagine workers as Server threads operating remotely.</p> <p>See installation guide for this mode: Worker To Database-FS</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker-to-server","title":"Worker to Server","text":"<p>This method implies that the workers do not have direct access to the database or the server file system.</p> <p>All communication occurs through the network, with workers accessing the server backend directly.</p> <p>Set the environment variable <code>VIX_MODE</code> to WORKER and set <code>VIX_SERVER</code> with the full address of the Server(including port number).</p> <p>Note</p> <p><code>VIX_HOST</code>, <code>VIX_PORT</code>, <code>DATABASE_URI</code> will be ignored, as the worker in this mode does not need it.</p> <p>In this use case, the vix_tasks_files directory will contain only temporary files; after uploading results to the Server, the results from the worker instance will be cleared.</p> <p>For authentication on the server worker will use <code>WORKER_AUTH</code> environment variable, which must contain \"USER_ID:PASSWORD\".</p> <p>Note</p> <p>Workers with an administrator account can process all tasks of all users, workers assigned to a user account can only process tasks created by that user.</p>"},{"location":"Flows/","title":"Available Flows","text":"<p>Note</p> <p>Results of Flows time execution is now located at Hardware Test Results</p> <ul> <li>Colorful XL</li> <li>Juggernaut Lite</li> <li>Juggernaut XL</li> <li>Mobius XL</li> <li>SDXL Lighting</li> <li>Hunyuan DiT</li> <li>Stable Cascade</li> <li>Playground 2.5 Prometheus</li> <li>Playground 2.5 Aesthetic</li> <li>Ghibli Portrait</li> <li>Comicu Portrait</li> <li>Vintage Portrait</li> <li>Memoji Portrait</li> <li>Sketch Portrait</li> <li>Photomaker 1</li> <li>Photomaker 2</li> <li>Photo Stickers</li> <li>Photo Stickers 2</li> <li>Mad Scientist</li> <li>Supir Upscaler</li> <li>Human Face Detailer</li> <li>Flux 1</li> <li>Inpaint</li> <li>AllYourLife</li> </ul>"},{"location":"Flows/AllYourLife/","title":"All Your Life","text":"<p>Original Workflow by Datou.</p> <p>Workflow is quite demanding, 8 images in a batch generates throw 2 nodes using 8 steps in each(128 steps total) - so it if not blazing fast.</p> <p>Photos are best given when person are relatively young or middle-aged.</p> <p>Don't even try to give photos of an old person unless you want to get a video from a horror movie.</p>"},{"location":"Flows/AllYourLife/#examples","title":"Examples","text":""},{"location":"Flows/Colorful_XL/","title":"Colorful XL","text":"<p>A fairly simple flow at the moment, simply using the latest Colorful XL model without any post-processing.</p> <p>Warning</p> <p>Not Safe for Work (NSFW) version.</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Colorful_XL/#examples","title":"Examples","text":"<pre><code>portrait, half-robot woman, in the dark, contrasting light, realistic, masterpiece\n</code></pre> <pre><code>half-cat woman, in the forest, vivid lights, realistic, masterpiece\n</code></pre> <ul> <li>Fast Run: true, Vibrancy: 3</li> </ul> <pre><code>portrait, young man, angel, sky, sun, high contrast\n</code></pre> <ul> <li>Fast Run: true, Vibrancy: 2, Steps number to generate: 60</li> </ul>"},{"location":"Flows/ComicuPortrait/","title":"ComicU Anime Portrait","text":"<p>Create an anime(sketch by default) image from a photo of a person.</p> <p>Prompt is optional, something like emotions can be used there: smile, sad, serious, etc.</p> <p>If you ticked the \"Disable Simple style\" you can try to add something like line-sketch to the prompt.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/ComicuPortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Shakira</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Flux_1/","title":"Flux 1","text":"<p>FLUX.1 is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. For more information, please read blog post</p> <p>The model is extremely demanding on hardware.</p> <p>Even on 24 Gigabytes, the speed of the model in the full version leaves much to be desired, since this basic flow does not fit completely into the video card cache.</p> <p>Lightning versions are quite good and generate quite good pictures in 4 steps.</p> <p>Totally with these models there are 4 different flows:</p> <ul> <li>Flux</li> <li>Flux (Small)</li> <li>Flux Lighting</li> <li>Flux Lighting (Small)</li> </ul> <p>Supports various aspect ratios.</p> <p>Supports different number of steps for non-Lighting versions.</p>"},{"location":"Flows/Flux_1/#flux-small-example","title":"Flux Small Example","text":"<pre><code>photo-realistic portrait of a cute kitten in cyberpunk style holding sign \"Visionatrix\" in ultra quality with high details\n</code></pre>"},{"location":"Flows/Flux_1/#flux-lighting-example","title":"Flux Lighting Example","text":"<pre><code>A cool man is driving a luxury car through a night city. The scene captures the vibrant nightlife with glowing neon signs, tall skyscrapers, and bustling streets. The dad is stylishly dressed, exuding confidence and charisma. The luxury car, sleek and modern, reflects the city lights, enhancing the atmosphere of urban sophistication and adventure.\n</code></pre>"},{"location":"Flows/Flux_1/#flux-example-50-steps","title":"Flux Example (50 steps)","text":"<pre><code>Portrait of beautiful woman in a swimsuit is lounging under a palm tree on a tropical beach. The scene is photorealistic, capturing the serene and picturesque setting with clear blue skies, gentle waves, and white sandy shores. The palm tree provides shade, and the overall atmosphere is one of leisure and tropical paradise.\n</code></pre>"},{"location":"Flows/GhibliPortrait/","title":"Ghibli Studio Portrait","text":"<p>Create an anime image from a person photo.</p> <p>Prompt is optional, something like emotions can be used there: smile, sad, serious, etc.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/GhibliPortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Shakira</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/HumanFaceDetailer/","title":"Human Face Detailer","text":"<p>Initially this was part of Playground 2.5 Aesthetics Flow until Visionatrix 1.0 version.</p> <p>It was decided to move it to a separate flow, so that it would be convenient to send the result of any flow here.</p> <p>This flow works by default at the moment on the CPU.</p> <p>The maximum number of faces for redrawing on a portrait is limited to 3.</p> <p>If no faces are found in the input image, nothing will be redrawn.</p>"},{"location":"Flows/HumanFaceDetailer/#examples","title":"Examples","text":""},{"location":"Flows/HunyuanDiT/","title":"HunyuanDiT","text":"<p>Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding.</p> <p>A solid model that supports natively very high Vibrancy.</p>"},{"location":"Flows/HunyuanDiT/#examples","title":"Examples","text":"<pre><code>portrait of a majestic insect\n</code></pre> <ul> <li>Vibrancy: 7, Steps: 60</li> </ul> <pre><code>close portrait of happy girl on the great wall\n</code></pre> <ul> <li>Vibrancy: 7, Steps: 60</li> </ul> <pre><code>portrait of a black pug on the yellow grass\n</code></pre> <ul> <li>Vibrancy: 6, Steps: 30</li> </ul>"},{"location":"Flows/Inpaint/","title":"Inpaint","text":"<p>Currently only a few inpaint flows are available:</p> <ul> <li>Flux Redraw</li> <li>Flux Redraw (Small)</li> <li>Flux Redraw Lighting (Small)</li> <li>ColorfulXL</li> </ul> <p>Inpainting is hard, you always need to try to select the correct Replacing factor parameter, and it strongly depends on the image and the flow.</p> <p>As examples, we will use real photos, it is harder to inpaint them, since they have a high resolution, and current models draw in 1024x1024 resolution.</p> <p>It is easier to \"repaint\" photos generated with AI, as they have usually low resolutions.</p>"},{"location":"Flows/Inpaint/#examples","title":"Examples","text":"<p>Original:</p> <p></p> <p>Results of painting long and lush luxurious hair:</p> <p> </p> <p>Results of painting on the left of the man:</p> <p> </p> <p>Results of painting Mooon the right of the man:</p> <p></p> <p>Original with baby photo:</p> <p></p> <p>Results of redrawing the upper part of the image:</p> <p> </p>"},{"location":"Flows/Juggernaut_Lite/","title":"Juggernaut Lite","text":"<p>This flow is most suitable for generating people quickly and realistically.</p> <p>Although it sometimes has problems with eyes or hands, in most cases the quality is quite acceptable.</p> <p>Supports various aspect ratios.</p>"},{"location":"Flows/Juggernaut_Lite/#examples","title":"Examples","text":"<pre><code>portrait of hero wearing cuirass sitting on the chair, high details, photo realistic\n</code></pre> <pre><code>portrait of elf man in obsidian armor looking at viewer from the dark, contrast, high details\n</code></pre> <pre><code>portrait rage tiger\n</code></pre>"},{"location":"Flows/Juggernaut_XL/","title":"Juggernaut XL","text":"<p>A fairly simple flow at the moment, simply using the latest Juggernaut X model without any post-processing.</p> <p>Note: Not Safe for Work (NSFW) version.</p> <p>Prompting information can be found here: Juggernaut-X prompting</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Juggernaut_XL/#examples","title":"Examples","text":"<pre><code>close portrait of hero wearing cuirass sitting on the chair, high details\n</code></pre> <pre><code>portrait of elf man in obsidian armor looking at viewer from the dark, contrast, high details\n</code></pre> <pre><code>portrait rage tiger, high resolution\n</code></pre>"},{"location":"Flows/MadScientist/","title":"Mad Scientist","text":"<p>This feature requires vision capabilities.</p> <p>You must either have the Ollama server running with the llava:7b-v1.6-vicuna-q8_0 model, or provide a <code>Gemini API key</code> in the settings.</p> <p>There are only two required arguments:</p> <ol> <li>Source file with a person's face.</li> <li>The file from which style will be created and applied to the source file.</li> </ol> <p>The results of this flow are amazing.</p>"},{"location":"Flows/MadScientist/#hardware-requirements","title":"Hardware requirements","text":"<p>Depends on whether the Ollama server is running locally or remotely.</p> <p>It can run on Macbook 32GB (including Ollama running locally on the same device)</p> <p>Since the Ollama model used here requires 7GB models and uses SDXL models from the workflow, it will likely require a 16GB memory card to run it on the GPU.</p> <p>But you can always run Ollama on a CPU or other device and after that a 10GB graphics card will be enough.</p>"},{"location":"Flows/MadScientist/#examples","title":"Examples","text":""},{"location":"Flows/MemojiPortrait/","title":"Memoji Portrait","text":"<p>Create cute Memoji from a photo of a person.</p> <p>Prompt is required, simplest examples is: <code>girl, portrait, close up</code></p> <pre><code>To make it look more like Memoji you can add **sico style** words:\n`**sico style**, girl, portrait, close up`\n</code></pre> <p>Person's face pose is optional.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/MemojiPortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Einstein</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Mobius_XL/","title":"Mobius XL","text":"<p>A fairly simple flow at the moment, simply using the latest Mobius model without any post-processing.</p> <p>This is a very unusual model, although it is part of the SDXL family of models - its results in some areas are simply amazing.</p> <p>It has better text drawing capabilities than other SDXL models.</p> <p>Since the author of this model is constantly improving it, we will update it with new versions when they are published.</p> <p>Here is a link to civitai to learn more about the model.</p> <p>Link to the author of the model on Twitter</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Mobius_XL/#examples","title":"Examples","text":"<pre><code>emotional owl looks at the viewer in surprise, masterpiece, cinematic, best quality\n</code></pre> <pre><code>very angry emotional pug, future, best quality, masterpiece, cinematic, (\"VIX\" text logo)\n</code></pre> <pre><code>portrait of male paratrooper, explosions background, masterpiece, cinematic, best quality\n</code></pre>"},{"location":"Flows/PhotoStickers/","title":"Photo Stickers","text":"<p>Turns a photo into 4 anime stickers with different emotions.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/PhotoStickers/#examples","title":"Examples","text":"<p>As input file, the photo of <code>Bruce Lee</code> was taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/PhotoStickers2/","title":"Photo Stickers 2","text":"<p>This feature requires vision capabilities.</p> <p>You must either have the Ollama server running with the llava:7b-v1.6-vicuna-q8_0 model, or provide a <code>Gemini API key</code> in the settings.</p> <p>Turns a photo into 4 stickers using different prompts.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p> <p>Original flow/idea examples: StickerYou - 1 photo for stickers</p>"},{"location":"Flows/PhotoStickers2/#examples","title":"Examples","text":"<p>As input file, the photo of <code>Bruce Lee</code> was taken from the Internet and used with default prompts.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Photomaker_1/","title":"Photomaker","text":"<p>Creates fairly good and realistic images of a person in different styles based on one photo. The person's face in the incoming image should preferably occupy most of the screen.</p> <p>Advanced parameter Accuracy currently applies only to one result image.</p> <p>Note</p> <p>Recommended words to be present in the prompt: woman/girl/man/boy</p>"},{"location":"Flows/Photomaker_1/#examples","title":"Examples","text":"<p>The image of <code>Bruce Lee</code> was taken from the Internet and used as a basis for first two prompts,     for the third prompt <code>Erin Starlight</code> photo was used.</p> <p> </p> <pre><code>portrait of man photomaker in green suite with dragons\n</code></pre> <ul> <li>Style: Cinematic</li> </ul> <p> </p> <pre><code>portrait of man photomaker looking at viewer from the dark, fire and flames\n</code></pre> <ul> <li>Style: Neonpunk</li> </ul> <p> </p> <pre><code>portrait of woman photomaker wearing suite in the forest looking at viewer\n</code></pre> <ul> <li>Style: Comic book</li> </ul>"},{"location":"Flows/Photomaker_2/","title":"Photomaker 2","text":"<p>This flow is based on the second version of Tencent's model. Its results are significantly better, but there are a few caveats:</p> <ol> <li> <p>The flow is highly sensitive to the input photos and their angles.</p> <p>(ideally, you should provide 3 photos: a profile, slightly from the left, and slightly from the right)</p> </li> <li> <p>At least 2 photos are required, but sometimes 3-4 are needed to achieve acceptable results.</p> </li> </ol> <p>Note</p> <p>We have added face cropping and background removal to this flow, si no need to select an input where the face occupies a large portion of the image.</p> <p>This flow produces 3 results instead of 2, so it takes a bit longer to process.</p> <p>Advanced parameter Accuracy currently applies only to two of the three result images.</p> <p>Recommended words to include in the prompt: woman/girl/man/boy</p>"},{"location":"Flows/Photomaker_2/#examples","title":"Examples","text":"<p>The images of <code>Albert Einstein</code>, <code>Avril Lavigne</code>, and <code>Tim Cook</code> were taken from the Internet and used as a base.</p> <p> </p> <pre><code>photo of a very happy man\n</code></pre> <ul> <li>Style: Neopunk</li> </ul> <p> </p> <pre><code>photo of a warrior girl\n</code></pre> <ul> <li>Style: No Style</li> </ul> <p> </p> <pre><code>photo of an angry ancient soldier man\n</code></pre> <ul> <li>Style: Photographic (Default)</li> </ul>"},{"location":"Flows/Playground_2_5_aesthetic/","title":"Aesthetic images (Playground 2.5)","text":"<p>The flow focuses on three key improvements: enhancing color and contrast, generating images across multiple aspect ratios, and aligning outputs with human aesthetic preferences.</p> <p>It demonstrates superior performance over previous models and commercial systems in terms of aesthetic quality, especially in generating vibrant colors, accommodating different aspect ratios, and capturing fine details in human-centric images.</p> <p>Playground v2.5 outperforms widely-used models and even some closed-source systems in user studies focusing on aesthetic preferences.</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Playground_2_5_aesthetic/#examples","title":"Examples","text":"<p>The second is an image with the \"fast run\" option</p> <p> </p> <pre><code>girl in suite looking at viewer, high quality, 8k, bright colors\n</code></pre> <p> </p> <pre><code>cat in suite looking at viewer, high quality, 8k, bright colors\n</code></pre> <p> </p> <pre><code>Dragon in forest, vivid colors\n</code></pre>"},{"location":"Flows/Playground_2_5_prometheus/","title":"Prometheus (Playground 2.5)","text":"<p>PrometheusV is presumed to be the first full rank finetune of Playground v2.5, developed by the creator of the Proteus model. This text-to-image generation model has been specifically adapted to enhance accessibility for the open-source community.</p> <p>PrometheusV1 represents a significant effort to make advanced text-to-image generation more accessible to the open-source community. Built upon the Playground v2.5 architecture, it has undergone a full rank finetune using an extensive dataset of over 400,000 images from the Proteus collection.</p> <p>A key aspect of its development was the removal of custom sampling methods through brute force techniques at scale, allowing the model to work more seamlessly with standard open-source tools and pipelines. Additionally, PrometheusV1 has been made backwards compatible with most SDXL LoRAs and tools.</p> <p>This approach aims to balance the model's performance capabilities with wider compatibility and ease of use. Users can expect outputs that reflect the model's intensive training on the large Proteus dataset while benefiting from improved interoperability with common open-source frameworks and existing SDXL ecosystem.</p> <p>Supports various aspect ratios.</p>"},{"location":"Flows/Playground_2_5_prometheus/#examples","title":"Examples","text":"<pre><code>portrait of gothic girl in suite looking at viewer, darkness, high quality\n</code></pre> <pre><code>close up portrait of devil in rage, high detail, ultra quality\n</code></pre> <ul> <li>steps: 40</li> </ul> <pre><code>the kindest kitten with wings, oil painting, high detail, soft colors\n</code></pre> <ul> <li>steps: 40</li> </ul>"},{"location":"Flows/SDXL_Lighting/","title":"SDXL Lighting","text":"<p>SDXL-Lightning is a fast text-to-image generation model. It can generate high-quality 1024px images in a few steps.</p>"},{"location":"Flows/SDXL_Lighting/#examples","title":"Examples","text":"<pre><code>A girl smiling\n</code></pre> <pre><code>lighting hero, anime\n</code></pre> <pre><code>portrait angry bear looking at viewer, vivid colours\n</code></pre>"},{"location":"Flows/SketchPortrait/","title":"Sketch Portrait","text":"<p>Quick creation of an anime sketch from a photograph of a person.</p> <p>Prompt is optional, something like emotions can be used there: smile, sad, serious, etc.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is very fast and convenient for everyday use.</p>"},{"location":"Flows/SketchPortrait/#examples","title":"Examples","text":"<p>The input files were taken from the Internet and used photographs of <code>Shakira</code>, <code>Steve Jobs</code> and <code>Eminem</code>.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Stable_Cascade/","title":"Stable Cascade","text":"<p>This flow works much better with text rendering, and supports repeated rendering to generate images in increased resolution with more detail.</p> <p>Suitable for various fairy-tale or cartoon images or for generating postcards.</p> <ul> <li> <p>One pass image resolution: 1024x576</p> </li> <li> <p>Two pass image resolution: 1536x864</p> </li> <li> <p>Three pass image resolution: 2048x1152</p> </li> </ul>"},{"location":"Flows/Stable_Cascade/#examples","title":"Examples","text":"<pre><code>portrait of bee, high details, 8k, vivid colors, contrast light\n</code></pre> <pre><code>dolphin at sea, dawn, high details, 8k, vivid colors, contrast light\n</code></pre> <ul> <li>Second Pass: false</li> </ul> <pre><code>girl with sign 'Cascade', high details, 8k, cinematic\n</code></pre>"},{"location":"Flows/SupirUpscaler/","title":"SUPIR Upscaler","text":"<p>This workflow is added mostly for research purposes, it is still in development.</p> <p>Memory requirements(both VRAM and RAM) are directly related to the input image resolution.</p> <p>Currently, for macOS runners <code>Diffusion type</code> must be set to fp32.</p> <ul> <li><code>Low memory mode</code>: reduces the size of processed tiles to 256.</li> </ul> <p>Note</p> <p>If you have a very small input image and the result is less than 1024 (512 for low memory mode) pixels in width or height, tiles should be disabled.</p> <p>From ComfyUI-SUPIR repo:</p> <pre><code>Memory requirements are directly related to the input image resolution.\nIn my testing I was able to run 512x512 to 1024x1024 with a 10GB 3080 GPU,\nand other tests on 24GB GPU to up 3072x3072.\n\nSystem RAM requirements are also hefty, don't know numbers\nbut I would guess under 32GB is going to have issues, tested with 64GB.\n</code></pre>"},{"location":"Flows/SupirUpscaler/#examples","title":"Examples","text":"<p>This Upscaler is still in development stage, results may be get better.</p> <p>We specifically place one portrait example where results is not perfect.</p> <p>But for many tests we performed - portrait scaling is shiny compared to older scaling methods.</p> <p>Image of a classic car:</p> <p></p> <p></p> <p>Jackie Chan portrait:</p> <p></p> <p></p> <p>Shakira:</p> <p></p> <p></p>"},{"location":"Flows/VintagePortrait/","title":"Vintage Portrait","text":"<p>Create a vintage 20th century portrait from a photo of a person.</p> <p>Prompt is required, simplest examples is: [portrait of a girl, cinematic, masterpiece[</p> <p>Person's face pose is optional.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/VintagePortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Shakira</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/","title":"ComfyUI to Visionatrix migration","text":"<p>If you want to adopt your ComfyUI workflow to use in Visionatrix, you can use this guide to help you do so. There are a few steps you need to follow.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#1-install-comfyui-visionatrix-custom-nodes","title":"1. Install ComfyUI-Visionatrix custom nodes","text":"<p>First, it is recommended to install our custom ComfyUI-Visionatrix nodes. Otherwise, you will have to use custom nodes titles which are will be parsed by Visionatrix.</p> <pre><code>git clone https://github.com/Visionatrix/ComfyUI-Visionatrix.git\n</code></pre> <p>Note</p> <p>You can do the required migration via nodes titles, which is less convenient. The node title must be like this: <code>input;Display Name;optional;advanced;order=1;custom_id=custom_name</code>.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#2-define-the-input-params","title":"2. Define the input params","text":"<p>Visionatrix UI aims simplicity and clarity. Define the most important input params of your ComfyUI workflow to extract them to the Visionatrix UI as inputs, for example:</p> <ul> <li>prompt (textarea)</li> <li>negative prompt (textarea)</li> <li>prompt strength (range)</li> <li>some logic toggles (checkbox)</li> <li>input files (file)</li> </ul> <p>For that you will need to attach our custom nodes as adapters to your nodes receiving these inputs that will be filled by the user from the Visionatrix UI.</p> <p>As example, you can have a look at our list of worklows adopted to the new format.</p> <p>Note</p> <p>The list of available nodes can be found in the readme of the ComfyUI-Visionatrix repository.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#21-node-to-input-mapping-via-title-string","title":"2.1 Node to Input mapping via title string","text":"<p>Alternatively, Visionatrix supports other Nodes mapping as an input param via node title string separated by semicolon.</p> <p>The nodes titles starting with <code>input;</code> keyword are considered input parameters to Visionatrix.</p> <p>The parameters list:</p> <ul> <li><code>input</code> - keyword to define the input param</li> <li><code>Display Name</code> - positional parameter, the name of the input field     displayed in the UI</li> <li><code>optional</code> - if present, the optional field is set to True</li> <li><code>advanced</code> - if present, the advanced field is set to True</li> <li><code>order=1</code> - the order of the input param in the UI</li> <li><code>custom_id=custom_name</code> - the custom id of the input param</li> </ul>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#22-external-nodes-used-via-node-to-input-mapping","title":"2.2 External nodes used via Node to Input mapping","text":"<p>In our workflows, we use some external nodes mapped as input params, that you can use as example:</p> <ul> <li><code>SDXLAspectRatioSelector</code> - select input field used from     comfyui-art-venture     for Aspect Ratio select. Usually it's an optional and hidden to the     advanced prompt options:     <code>input;Aspect Ratio;optional;advanced;custom_id=aspect_ratio</code>;</li> <li><code>LoadImage</code> - default ComfyUI image loader node as image file input     field. As required title: <code>input;Input image;order=1</code>, or optional     advanced: <code>input;Optional helper image;optional;advanced;order=20</code>;</li> </ul>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#3-map-the-models-for-automatic-download","title":"3. Map the models for automatic download","text":"<p>Visionatrix simplifies and automates the process of downloading the models.</p> <p>You need to ensure that models used in workflow are known to Visionatrix, see models catalog</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#4-build-the-list-of-available-flows","title":"4. Build the list of available flows","text":"<p>The last step is to build the list of available flows in the Visionatrix UI. Follow the steps described in options.py file for <code>FLOWS_URL</code> and <code>MODELS_CATALOG_URL</code> to enable Visionatrix local workflows development mode:</p> <p>Create a zip with adjusted/new flows:</p> <pre><code>cd ../VixFlowsDocs &amp;&amp; zip -r ../Visionatrix/flows.zip flows &amp;&amp; cd ../Visionatrix\n</code></pre> <p>And uncomment appropriate code lines in options.py file to use local versions of the flows.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#5-verify-and-test-the-workflow","title":"5. Verify and test the workflow","text":"<p>Last step is to run Visionatrix and set up your workflow to verify that everything works as expected.</p>"},{"location":"FlowsDeveloping/gated_models/","title":"Gated Models","text":"<p>Sometimes, the model you want to use requires authentication to access it. These are referred to as Gated Models.</p> <p>Flows with such models are distinctly marked in the Visionatrix UI.</p> <p>To install such a flow, you need to provide an <code>Access Token</code> for HuggingFace or an <code>API Key</code> for CivitAI.</p>"},{"location":"FlowsDeveloping/gated_models/#huggingface-token","title":"HuggingFace Token","text":"<p>Steps to access gated models from HuggingFace:</p> <ol> <li>Register on HuggingFace if you are not already registered.</li> <li>Generate an access token in the settings of HuggingFace (click on your icon \u2192 Settings \u2192 Access Tokens).</li> <li>Click <code>Set Permissions</code> for the token after generation and select <code>Read access to contents of all public gated repos you can access</code>.</li> <li>Enter this access token in the Visionatrix settings.</li> <li>Gain access to the model on your account by visiting its page (you can click on the model from the Visionatrix UI) and filling out the required form.</li> </ol>"},{"location":"FlowsDeveloping/gated_models/#civitai-api-key","title":"CivitAI API Key","text":"<p>Steps to access gated models from CivitAI:</p> <ol> <li>Register on CivitAI if you are not already registered.</li> <li>Create an API key in the settings of CivitAI (click on your icon \u2192 Add API Key).</li> <li>Enter this API key in the Visionatrix settings.</li> <li>Gain access to the model on your account by visiting its page (you can click on the model from the Visionatrix UI) and filling out the required form.</li> </ol>"},{"location":"FlowsDeveloping/gated_models/#connecting-a-worker-to-process-flows-with-gated-models","title":"Connecting a Worker to Process Flows with Gated Models","text":"<p>If you want to connect your own worker to process flows with gated models, note that user workers cannot receive global access tokens from the server to prevent leaks. You have two options:</p> <ol> <li>Download the model yourself and place it in the folder specified in <code>models_catalog.json</code> under the <code>filename</code> or <code>types</code> keys.</li> <li>Set the <code>HF_AUTH_TOKEN</code> environment variable with your own public access token. The worker will then be able to install flows with gated models from HuggingFace.</li> <li>For CivitAI, set the environment variable <code>CA_API_KEY</code>.</li> </ol>"},{"location":"FlowsDeveloping/models_catalog/","title":"Adding New Model to Catalog","text":""},{"location":"FlowsDeveloping/models_catalog/#introduction","title":"Introduction","text":"<p>Visionatrix uses a <code>models_catalog.json</code> file to automatically map nodes in ComfyUI workflows to their corresponding models, ensuring a seamless user experience.</p> <p>If you use a model that is missing in the current catalog, you can now easily add it using our new Model Catalog Editor tool.</p> <p>This tool helps you create consistent and accurate entries in <code>models_catalog.json</code> by guiding you through setting the model\u2019s URL, homepage, filename, hash, and classification (\"types\").</p>"},{"location":"FlowsDeveloping/models_catalog/#optional-auth-tokens","title":"Optional Auth Tokens","text":"<p>If you have authentication tokens for Hugging Face or CivitAI, the tool can use them to fetch metadata and check gated models. It will attempt to read these tokens from the Visionatrix database if available.</p> <p>The script looks for the database in the <code>../Visionatrix</code> directory, so if both repositories are cloned in the same parent directory, the setup should work seamlessly.</p> <p>Note</p> <p>Lack of access to the database or missing tokens does not prevent adding models, but certain features (like checking gated models) may be limited.</p>"},{"location":"FlowsDeveloping/models_catalog/#launching-the-editor","title":"Launching the Editor","text":"<p>The <code>models_catalog_editor.py</code> file is located in the <code>VixFlowsDocs</code> repository at its root. You will also find a <code>requirements_catalog_editor.txt</code> file there. To start:</p> <ol> <li>Install Dependencies (if needed):</li> </ol> <pre><code>pip install -r requirements_catalog_editor.txt\n</code></pre> <ol> <li>Run the Editor:</li> </ol> <pre><code>python models_catalog_editor.py\n</code></pre> <p>This opens a GUI window:</p> <p></p>"},{"location":"FlowsDeveloping/models_catalog/#using-the-model-catalog-editor","title":"Using the Model Catalog Editor","text":""},{"location":"FlowsDeveloping/models_catalog/#step-1-provide-the-model-source-url","title":"Step 1: Provide the Model Source URL","text":"<p>In the \"URL\" field, enter the direct link to your model. Supported sources:</p> <ul> <li> <p>Hugging Face: e.g., <code>https://huggingface.co/{user}/{repo}/blob/main/model.safetensors</code> The editor automatically corrects <code>/blob/</code> links to <code>/resolve/</code> if necessary.</p> </li> <li> <p>CivitAI: Provide a link that includes a <code>modelVersionId</code> query parameter or a link to a model/version page. The tool will attempt to fetch metadata and files associated with that model.</p> </li> </ul> <p>Click Process. The editor then tries to:</p> <ul> <li>Fetch a homepage URL.</li> <li>Propose a default filename.</li> <li>Check if the model is gated (requires auth token).</li> <li>For CivitAI, it lists all available files and their hashes, prompting you to choose one if multiple are found. It also attempts to determine the correct model <code>type</code> from the metadata.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-2-confirm-or-edit-the-download-url-homepage-and-filenames","title":"Step 2: Confirm or Edit the Download URL, Homepage, and Filenames","text":"<ul> <li>Download URL: The tool sets this automatically for known sources. You can adjust it if needed.</li> <li>Homepage: For Hugging Face, this is usually the repository root. For CivitAI, it's the model\u2019s main page. You can also enter a custom homepage if necessary.</li> <li>Filenames:   The editor attempts to determine a good filename. If your model came from Hugging Face and also exists on CivitAI, you might see a \"HugFace name\" and a \"CivitAI name\".   If the suggested filenames are not suitable (e.g., too generic like <code>model.safetensors</code>), provide a \"Force Filename\" to ensure uniqueness and clarity.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-3-verify-the-hash","title":"Step 3: Verify the Hash","text":"<p>The editor tries to fetch a SHA256 hash for the model:</p> <ul> <li>For Hugging Face models with a supported configuration, it reads the <code>X-Linked-ETag</code> header as a hash.</li> <li>For CivitAI models, it uses the provided file hash from the metadata.</li> </ul> <p>If the hash is not found, enter it manually in the \"Hash\" field. The hash is crucial for ensuring model integrity and facilitating quick checks by Visionatrix.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-4-set-model-types","title":"Step 4: Set Model \"Types\"","text":"<p>\"Types\" determines where the model file will be stored inside ComfyUI\u2019s directory structure. Common types include:</p> <ul> <li><code>checkpoints</code></li> <li><code>diffusion_models</code></li> <li><code>loras</code></li> <li><code>controlnet</code></li> <li><code>embeddings</code></li> <li><code>vae</code></li> <li>... and more.</li> </ul> <p>The tool tries to infer a type from the model\u2019s metadata. However, for certain models (like SD3.5 or Flux models), the correct type may not be determined automatically. In such cases, you must manually select the correct type from the checkboxes.</p> <p>Tip: If unsure, consider:</p> <ul> <li><code>diffusion_models</code> or <code>checkpoints</code> for base diffusion models.</li> <li><code>loras</code> for LoRA-based models.</li> <li><code>controlnet</code> for ControlNet-based models.</li> <li><code>embeddings</code> for textual inversion embeddings.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-5-set-gated-if-needed","title":"Step 5: Set Gated (if Needed)","text":"<p>If the model is gated (e.g., private or requires a Hugging Face token to download), check the \"Gated\" box. This ensures Visionatrix knows it needs an authorization token for downloading.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-6-define-the-regexes","title":"Step 6: Define the Regexes","text":"<p>Regexes help Visionatrix identify which model entry applies to a given node in a ComfyUI workflow. You can set:</p> <ul> <li><code>class_type</code> regex: Matches the ComfyUI node\u2019s <code>class_type</code>.</li> <li><code>input_name</code> regex: Matches the input parameter name of the node parameter that holds the model filename.</li> <li><code>input_value</code> regex: Required to match the actual input value from the workflow (e.g., the filename or part of it).</li> </ul> <p>Important: - <code>input_value</code> is mandatory. It should match the final filename or a portion of it. - Use a pattern that is flexible enough to capture variations in filenames, but not so broad it conflicts with other models.</p> <p>For example, if your filename is <code>my-special-model.safetensors</code>, a suitable <code>input_value</code> might be:</p> <pre><code>(?i)(?:[^\\/\\\\]*[\\/\\\\]?)?my-special-model\\.safetensors$\n</code></pre> <p>If you have multiple filenames (like a Hugging Face name and a CivitAI name), the tool tries to create a regex that matches them all. Adjust the regex if necessary to ensure uniqueness and correctness.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-7-save-the-entry","title":"Step 7: Save the Entry","text":"<p>Once you have verified all fields:</p> <ul> <li>Click Save.</li> <li>Choose or confirm a unique model name key. The tool ensures no conflicts with existing keys. If there's a hash conflict, you can overwrite or rename the key.</li> <li>On successful save, the model entry is added to <code>models_catalog.json</code>.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#conclusion","title":"Conclusion","text":"<p>With this utility, adding new models has become easy and efficient.</p> <p>After saving your changes locally, consider sharing your <code>models_catalog.json</code> updates by submitting a pull request to the VixFlowsDocs repository.</p>"},{"location":"FlowsDeveloping/technical_information/","title":"Technical Information","text":""},{"location":"FlowsDeveloping/technical_information/#bundled-comfyui-nodes","title":"Bundled ComfyUI nodes","text":"<p>Visionatrix by default install and update these nodes:</p> <ul> <li>ComfyUI-AutoCropFaces</li> <li>ComfyUI_BiRefNet_ll</li> <li>ComfyUI-Custom-Scripts</li> <li>ComfyUI-Impact-Pack</li> <li>comfyui-ollama</li> <li>ComfyUI-SUPIR</li> <li>ComfyUI-Visionatrix</li> <li>ComfyUI-WD14-Tagger</li> <li>comfyui_controlnet_aux</li> <li>ComfyUI_essentials</li> <li>ComfyUI_FizzNodes</li> <li>ComfyUI-Gemini</li> <li>ComfyUI_InstantID</li> <li>ComfyUI_IPAdapter_plus</li> <li>ComfyUI_UltimateSDUpscale</li> <li>efficiency-nodes-comfyui</li> <li>PuLID_ComfyUI</li> <li>rgthree-comfy</li> <li>Skimmed_CFG</li> <li>was-node-suite-comfyui</li> <li>ComfyUI-Inpaint-CropAndStitch</li> <li>ComfyUI-PhotoMaker-Plus</li> <li>ComfyUI-VideoHelperSuite</li> <li>ComfyUI-Frame-Interpolation</li> <li>ComfyUI-KJNodes</li> <li>ComfyUI_LayerStyle</li> <li>ComfyUI-Easy-Use</li> <li>ComfyUI_PuLID_Flux_ll</li> </ul> <p>We are gradually expanding the list.</p> <p>The main reason many components are missing is that they are quite difficult to install, and we believe that an easy installation process is more important in most cases.</p>"},{"location":"FlowsDeveloping/technical_information/#workflows-storage","title":"Workflows Storage","text":"<p>All public flows are located in the VixFlowsDocs repository.</p> <p>The repository consists of a development branch main and a set of branches version-X.Y:</p> <ul> <li>version-0.5</li> <li>version-0.6</li> <li>...</li> <li>version-1.0</li> <li>version-1.1</li> <li>main</li> </ul> <p>Sets of public workflows are packaged in the root of the documentation and have the following form:</p> <ul> <li>flows-0.5.zip</li> <li>flows-0.6.zip</li> <li>...</li> <li>flows-1.0.zip</li> <li>flows-1.1.zip</li> <li>flows.zip</li> </ul> <p>The development version of Visionatrix fetches the <code>flows.zip</code> archive by default.</p> <p>Release versions of Visionatrix fetch sets of flows for their version.</p>"},{"location":"FlowsDeveloping/technical_information/#configuring-flows-sources","title":"Configuring Flows Sources","text":"<p>The <code>FLOWS_URL</code> variable in Visionatrix has the default value of:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>You can specify multiple URLs or paths to flow archives by separating them with semicolons <code>;</code>.</p> <p>When an element in the FLOWS_URL ends with <code>/</code>, Visionatrix fetches an archive with flows appropriate for its version:</p> <ul> <li>For development versions, it fetches <code>flows.zip</code>.</li> <li>For release versions, it fetches <code>flows-X.Y.zip</code>, where <code>X.Y</code> matches the major and minor Visionatrix version numbers.</li> </ul>"},{"location":"FlowsDeveloping/technical_information/#examples","title":"Examples","text":"<ol> <li> <p>Default Configuration:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>Visionatrix will fetch flows from the official repository corresponding to its version.</p> </li> <li> <p>Custom Flow Sources:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/;https://example.com/custom_flows.zip;/local/path/flows.zip\n</code></pre> <p>Visionatrix will fetch flows from:</p> <ul> <li>The official repository.</li> <li>A custom online archive at <code>https://example.com/custom_flows.zip</code>.</li> <li>A local archive at <code>/local/path/flows.zip</code>.</li> </ul> </li> </ol>"},{"location":"FlowsDeveloping/technical_information/#flow-merging-and-versioning","title":"Flow Merging and Versioning","text":"<ul> <li> <p>When multiple flows have the same name across different sources, Visionatrix will:</p> <ul> <li>Prefer the flow with the highest version number.</li> <li>If versions are equal, the flow from the first source in the <code>FLOWS_URL</code> list takes precedence.</li> </ul> </li> <li> <p>This allows you to override or supplement the default flows with custom ones.</p> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#notes","title":"Notes","text":"<ul> <li> <p>Local Paths: You can specify local paths to flow archives, which is useful during development or when working offline.</p> </li> <li> <p>URL Endings:</p> <ul> <li> <p>If a URL ends with <code>/</code>, Visionatrix automatically appends the appropriate <code>flows.zip</code> or <code>flows-X.Y.zip</code> based on its version.</p> </li> <li> <p>If a URL points directly to an archive (e.g., <code>https://example.com/custom_flows.zip</code>), Visionatrix will use that specific file.</p> </li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#models-storage","title":"Models Storage","text":"<p>All public models catalogs are located in the VixFlowsDocs repository.</p> <p>Similar to workflows, the repository consists of a development branch main and a set of branches version-X.Y:</p> <ul> <li>version-0.5</li> <li>version-0.6</li> <li>...</li> <li>version-1.0</li> <li>version-1.1</li> <li>main</li> </ul> <p>The models catalogs are available in the root of the documentation and have the following form:</p> <ul> <li>models_catalog-0.5.json</li> <li>models_catalog-0.6.json</li> <li>...</li> <li>models_catalog-1.0.json</li> <li>models_catalog-1.1.json</li> <li>models_catalog.json</li> </ul> <p>The development version of Visionatrix fetches the <code>models_catalog.json</code> by default.</p> <p>Release versions of Visionatrix fetch the models catalog for their version.</p>"},{"location":"FlowsDeveloping/technical_information/#configuring-models-catalog-sources","title":"Configuring Models Catalog Sources","text":"<p>The <code>MODELS_CATALOG_URL</code> variable in Visionatrix has the default value of:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>You can specify multiple URLs or paths to catalogs by separating them with semicolons <code>;</code>.</p> <p>When an element in the MODELS_CATALOG_URL ends with <code>/</code>, Visionatrix fetches the catalog appropriate for its version:</p> <ul> <li>For development versions, it fetches <code>models_catalog.json</code>.</li> <li>For release versions, it fetches <code>models_catalog-X.Y.json</code>, where <code>X.Y</code> matches the major and minor Visionatrix version numbers.</li> </ul>"},{"location":"FlowsDeveloping/technical_information/#examples_1","title":"Examples","text":"<ol> <li> <p>Default Configuration:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>Visionatrix will fetch the models catalog from the repository corresponding to its version.</p> </li> <li> <p>Custom Models Catalog Sources:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/;https://example.com/custom_models_catalog.json;/local/path/models_catalog.json\n</code></pre> <p>Visionatrix will fetch models catalogs from:</p> <ul> <li>The official repository.</li> <li>A custom online catalog at <code>https://example.com/custom_models_catalog.json</code>.</li> <li>A local catalog at <code>/local/path/models_catalog.json</code>.</li> </ul> </li> </ol>"},{"location":"FlowsDeveloping/technical_information/#models-merging-and-versioning","title":"Models Merging and Versioning","text":"<ul> <li> <p>When multiple models have the same name across different sources, Visionatrix will:</p> <ul> <li>Prefer the model from the source listed later in the <code>MODELS_CATALOG_URL</code> variable.</li> <li>Allow custom catalogs to override or supplement default models.</li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#notes_1","title":"Notes","text":"<ul> <li> <p>Local Paths: You can specify local paths to models catalogs, which is useful during development or when working offline.</p> </li> <li> <p>URL Endings:</p> <ul> <li> <p>If a URL ends with <code>/</code>, Visionatrix automatically appends the appropriate <code>models_catalog.json</code> or <code>models_catalog-X.Y.json</code> based on its version.</p> </li> <li> <p>If a URL points directly to a catalog (e.g., <code>https://example.com/custom_models_catalog.json</code>), Visionatrix will use that specific file.</p> </li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/","title":"Vix Workflows","text":""},{"location":"FlowsDeveloping/vix_workflows/#introduction","title":"Introduction","text":"<p>ComfyUI workflows are designed for developers and those interested in diffusion processes.</p> <p>Visionatrix workflows are created on top of ComfyUI workflows for easy deployment and straightforward use.</p> <p>Currently, there are two main issues with using ComfyUI flows for the public:</p> <ol> <li> <p>It's unclear where to get the model from and how to deploy/install it:</p> <p>deployment/installation issue</p> </li> <li> <p>Without some experience, it's unclear how to just provide inputs to simple get results:</p> <p>usability issue</p> </li> </ol>"},{"location":"FlowsDeveloping/vix_workflows/#automatic-models-mapping","title":"Automatic models mapping","text":"<p>To address the first issue with model mapping, Visionatrix includes a models_catalog.json file.</p> <p>By default, it is taken and updated from the Visionatrix repository on GitHub, in case you add a new flow and need to add new model mappings you can change its path using an environment variable to a local file path or add additional places from where to fetch it.</p> <p>Note</p> <p>UI for easily adding models without going into too much detail, you can find it on this documentation page.</p> <p>The file structure consists of a set of objects, each describing a ComfyUI Node class that loads or uses a model.</p> <pre><code>\"InstantID-ControlNet\": {\n    \"regexes\": [\n      {\n        \"class_name\": \"ControlNetLoader\",\n        \"input_value\": \"^(?=.*(?i:instantid)).*\"\n      }\n    ],\n    \"url\": \"https://huggingface.co/InstantX/InstantID/resolve/main/ControlNetModel/diffusion_pytorch_model.safetensors\",\n    \"homepage\": \"https://huggingface.co/InstantX/InstantID\",\n    \"hash\": \"c8127be9f174101ebdafee9964d856b49b634435cf6daa396d3f593cf0bbbb05\",\n    \"types\": [\n      \"controlnet\"\n    ],\n    \"filename\": \"instantid-controlnet.safetensors\"\n  }\n</code></pre>"},{"location":"FlowsDeveloping/vix_workflows/#regexes","title":"\"regexes\"","text":"<p>Regexes are used to understand if this record related to the specified model from the ComfyUI workflow.</p> <p><code>\"input_name\"</code>, <code>\"class_name\"</code>, and <code>\"input_value\"</code> are supported, both together and separately.</p> <p>Note</p> <p>If these conditions prove insufficient, please create an issue and we will find a solution together.</p>"},{"location":"FlowsDeveloping/vix_workflows/#types","title":"\"types\"","text":"<p>This field lists one or more categories the model belongs to (e.g., <code>text_encoders</code>, <code>ipadapter</code>). It determines the folder where the model will be saved.</p> <p>If <code>types</code> is empty or missing, the <code>filename</code> is assumed to be located at the root of the ComfyUI folder.</p> <p>Together, <code>types</code> and <code>filename</code> should provide enough information to correctly place the model.</p>"},{"location":"FlowsDeveloping/vix_workflows/#filename","title":"\"filename\"","text":"<p>Overrides the default file name for the model.</p> <p>This is particularly useful when the model has a generic name (e.g., <code>\"model.safetensors\"</code>) that could conflict with others.</p> <p>Using a unique name avoids such conflicts.</p>"},{"location":"FlowsDeveloping/vix_workflows/#url","title":"\"url\"","text":"<p>Indicates where to download the model from if it is not already present.</p> <p>It is preferable for the model to be hosted on Hugging Face, but <code>civitai.com</code> is also supported.</p>"},{"location":"FlowsDeveloping/vix_workflows/#homepage","title":"\"homepage\"","text":"<p>An optional field with a link to the model's home page where you can view the license.</p>"},{"location":"FlowsDeveloping/vix_workflows/#hash","title":"\"hash\"","text":"<p>The SHA256 hash of the model. Used to verify the integrity of the model and check for download errors.</p>"},{"location":"FlowsDeveloping/vix_workflows/#vix-workflow-overview","title":"Vix workflow overview","text":"<p>In the Visionatrix the workflow consists of a single file: <code>flow_name.json</code>, which is a ComfyUI workflow file adopted to Visionatrix.</p> <p>Note</p> <p>The main difference between Visionatrix and ComfyUI:</p> <p>A task is created with a single request, which includes both incoming text parameters and input files.</p> <p>The flow metadata fields described below are filled in the <code>VixUi-WorkflowMetadata</code> node.</p>"},{"location":"FlowsDeveloping/vix_workflows/#name","title":"\"name\"","text":"<p>The name of the workflow. It usually matches the name of the file with workflow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#display_name","title":"\"display_name\"","text":"<p>Used in the UI to display the name of the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#description","title":"\"description\"","text":"<p>A brief description of the flow for user display.</p>"},{"location":"FlowsDeveloping/vix_workflows/#author","title":"\"author\"","text":"<p>The name of the ComfyUI flow author or the Visionatrix flow author.</p>"},{"location":"FlowsDeveloping/vix_workflows/#homepage_1","title":"\"homepage\"","text":"<p>A link that will open when clicking on the flow author's name.</p>"},{"location":"FlowsDeveloping/vix_workflows/#license","title":"\"license\"","text":"<p>The general license under which the flow can be used (to simplify understanding whether it can be used behind the API service, whether it can be used commercially, etc.)</p>"},{"location":"FlowsDeveloping/vix_workflows/#documentation","title":"\"documentation\"","text":"<p>Link to additional information about the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#tags","title":"\"tags\"","text":"<p>A list of string tags that can be used to label the categories of the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#input_params","title":"\"input_params\"","text":"<p>Note</p> <p>The input params are parsed automatically from the adopted ComfyUI workflow. Based on the information from this field, the Visionatrix UI dynamically displays the interface.</p> <p>Technically, this is a list of objects, where each object is one input parameter, which includes:</p> <ul> <li>\"name\" - the key(used only when <code>type</code> is equal <code>\"text\"</code>)</li> <li>\"display_name\" - the name of the parameter displayed in the UI</li> <li> <p>\"type\" - a string that can have values: <code>\"text\"</code> or <code>\"image\"</code></p> <p>Note</p> <p><code>\"video\"</code> and <code>\"audio\"</code> types will be added as soon as there is the first Workflow requiring it.</p> </li> <li> <p>\"optional\" - indicates whether the parameter is optional. If an     optional field is not provided, the backend will fill it in automatically.</p> </li> <li>\"advanced\" - used only in the UI, shows whether the field should     be hidden by default (we do not want to overload the interface for regular users)</li> <li> <p>\"default\" - the field value to initiate.</p> <p>Note</p> <p>Used for both UI and backend, but not mandatory even for optional fields (as in the ComfyUI flow, the Node value is still set)</p> </li> <li> <p>\"comfy_node_id\" - a field only for the backend, which defines what to do with this value (where to use it in the ComfyUI Flow)</p> </li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/#required_memory_gb","title":"\"required_memory_gb\"","text":"<p>This field indicates the amount of (video) memory in gigabytes required for the flow to work.</p> <p>By default, in Visionatrix, all flows not supported by the available hardware are hidden.</p>"},{"location":"FlowsDeveloping/vix_workflows/#calculating-required-memory","title":"Calculating <code>Required Memory</code>","text":"<p>To determine the appropriate <code>required_memory_gb</code> value for a flow (e.g., on a GPU with 24 GB of memory), follow these steps:</p>"},{"location":"FlowsDeveloping/vix_workflows/#adjusting-for-different-gpu-memory","title":"Adjusting for Different GPU Memory","text":"<p>If your GPU has less memory (e.g., 16 GB), reduce the calculated values accordingly (subtract 8 GB from the original values for a 24 GB card).</p>"},{"location":"FlowsDeveloping/vix_workflows/#steps-to-measure-memory-usage","title":"Steps to Measure Memory Usage","text":"<ol> <li> <p>Disable Smart Memory Management    Run ComfyUI with the following argument:    <code>--disable-smart-memory --reserve-vram=17.2</code></p> </li> <li> <p>Enable Execution Settings    Inside Visionatrix when launching Flow, navigate to:    Advanced Options -&gt; Execution Settings    Set the variables <code>X-WORKER-UNLOAD-MODELS</code> and <code>X-WORKER-EXECUTION-PROFILER</code> to <code>1</code>. Check the box for \"Enable Execution Settings\".</p> </li> <li> <p>Execute the Flow    Launch the task with \"Execution Settings\" enabled. After the task completes, click the ellipsis under the task and select \"Execution Details\".</p> </li> <li> <p>Review Maximum Memory Usage    In the Execution Details, look for a value labeled <code>\"max_memory_usage\"</code>. For example:    <code>\"max_memory_usage\": 3800.11</code>    This value represents the maximum memory usage in megabytes for the task.</p> </li> <li> <p>Convert Memory Usage to Gigabytes    Ensure that the <code>\"max_memory_usage\"</code> value does not exceed the desired <code>required_memory_gb</code>. Use this value to set the field appropriately.</p> </li> </ol>"},{"location":"FlowsDeveloping/vix_workflows/#important-notes","title":"Important Notes","text":"<ul> <li>For accurate measurements, ComfyUI must be launched with the <code>--disable-smart-memory</code> parameter, and <code>X-WORKER-UNLOAD-MODELS</code> must be set to <code>1</code>.</li> <li>While not all nodes support the <code>--reserve-vram</code> parameter, and some nodes like <code>Supir</code> may not reflect accurate <code>max_memory_usage</code> values due to their reset behavior, this approach is still much better than no estimation.</li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/#gpu-memory-settings-for-common-configurations","title":"GPU Memory Settings for Common Configurations","text":"<p>Here are recommended arguments for testing if a flow works on GPUs with specific memory configurations:</p> <ul> <li>6 GB cards: <code>--disable-smart-memory --reserve-vram=19.2</code></li> <li>8 GB cards: <code>--disable-smart-memory --reserve-vram=17.2</code></li> <li>12 GB cards: <code>--disable-smart-memory --reserve-vram=13.2</code></li> <li>16 GB cards: <code>--disable-smart-memory --reserve-vram=9.2</code></li> </ul>"},{"location":"IntegrationsManual/getting_started/","title":"Integrating Visionatrix: Getting Started","text":"<p>This guide will help you get started with programmatically interacting with Visionatrix.</p> <p>Note</p> <p>SDXL Lighting and Remove Background (Birefnet) flows should be installed on the Visionatrix instance.</p> <p>This guide only covers how to create tasks from a flow, fetch their progress, and receive the results.</p> <p>Info</p> <p>We constantly strive to make our API more comfortable to use with code generated by Claude, Qwen, or ChatGPT.</p> <p>However, this guide is primarily focused on understanding the lifespan of a task. It does not describe how to automatically create a Gradio application for the specified flow or any other such topics.</p>"},{"location":"IntegrationsManual/getting_started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Authentication</li> <li>Task Lifecycle</li> <li>Full Working Examples in Python<ul> <li>Example 1: Using the \"SDXL Lighting\" Flow</li> <li>Example 2: Using the \"Remove Background (Birefnet)\" Flow</li> </ul> </li> </ol>"},{"location":"IntegrationsManual/getting_started/#authentication","title":"Authentication","text":"<p>Visionatrix currently supports Basic Authentication only. Depending on the mode in which Visionatrix is running, you may or may not need to provide authentication credentials:</p> <ul> <li>SERVER Mode: If Visionatrix is running in SERVER mode, you must specify your username and password in your API requests.</li> <li>DEFAULT Mode: If Visionatrix is running in DEFAULT mode, no authentication is required.</li> </ul> <p>For the purposes of this guide, we will assume that authentication is required.</p> <p>By default, we use <code>admin</code> as both the username and password in our development setups for SERVER mode when testing Visionatrix. Replace these with your actual credentials if they are different.</p>"},{"location":"IntegrationsManual/getting_started/#task-lifecycle","title":"Task Lifecycle","text":"<p>The typical lifecycle of a task in Visionatrix involves the following steps:</p> <ol> <li> <p>Creating a Task: You send a <code>PUT</code> request to the <code>/vapi/tasks/create/{name}</code> endpoint, where <code>{name}</code> is the ID of the flow you want to use. The request must use <code>multipart/form-data</code> and include the necessary parameters for the flow.</p> </li> <li> <p>For the SDXL Lighting (<code>sdxl_lighting</code>) flow, required parameters are:</p> <ul> <li><code>prompt</code> (string): The text prompt for image generation.</li> <li><code>steps_number</code> (string): The number of steps to use.</li> </ul> </li> <li> <p>Optional Parameters:</p> <ul> <li><code>negative_prompt</code> (string): The \"negative\" text prompt for image generation.</li> <li><code>seed</code> (integer): The seed for random number generation. If not specified, a random seed will be used.</li> </ul> </li> <li> <p>For the Remove Background (Birefnet) (<code>remove_background_birefnet</code>) flow, required parameters are:</p> <ul> <li><code>input_image</code> (file): The image file from which to remove the background.</li> </ul> </li> <li> <p>Other Parameters:</p> <ul> <li>There are additional optional parameters such as <code>webhook_url</code>, <code>webhook_headers</code>, <code>translate</code>, <code>group_scope</code>, etc. These parameters are not covered in this beginner guide.</li> </ul> </li> <li> <p>Checking Task Progress: After creating a task, you can check its progress using the <code>/vapi/tasks/progress/{task_id}</code> endpoint. The response includes details such as the task's <code>progress</code>, <code>error</code> (if any), and a list of <code>outputs</code>.</p> </li> <li> <p>Progress Values:</p> <ul> <li><code>0.0</code>: Task is queued and has not started yet.</li> <li>Between <code>0.1</code> and <code>99.9</code>: Task is in progress.</li> <li><code>100.0</code>: Task is completed.</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>If the <code>error</code> field is not empty, the task has encountered an error.</li> <li>You can retry the task or investigate the issue based on the error message.</li> </ul> </li> <li> <p>Retrieving Task Results: Once a task is completed (<code>progress</code> reaches <code>100.0</code>), you can retrieve the results using the <code>/vapi/tasks/results</code> endpoint. The <code>outputs</code> from the task details contain a list of output nodes, each with a <code>comfy_node_id</code>. You should iterate over all the outputs to retrieve all results.</p> </li> <li> <p>To retrieve each result, you send a <code>GET</code> request to <code>/vapi/tasks/results</code> with the <code>task_id</code> and <code>node_id</code> (which is the <code>comfy_node_id</code> from the outputs).</p> </li> <li>The result files can then be saved locally. The format of the result file depends on the flow and the output node's type.</li> </ol> <p>Note</p> <p>We are currently in the process of automatically creating OpenAPI specifications for the flows: Flows API.</p> <p>You can easily take a look at the flow parameters there.</p>"},{"location":"IntegrationsManual/getting_started/#full-working-examples-in-python","title":"Full Working Examples in Python","text":"<p>Below are full working examples in Python using the <code>httpx</code> library. These scripts demonstrate how to create a task, check its progress, and retrieve all the results for both the <code>sdxl_lighting</code> and <code>remove_background_birefnet</code> flows.</p> <p>Before running the scripts, make sure you have the <code>httpx</code> library installed:</p> <pre><code>pip install httpx\n</code></pre>"},{"location":"IntegrationsManual/getting_started/#example-1-using-the-sdxl-lighting-flow","title":"Example 1: Using the \"SDXL Lighting\" Flow","text":"<pre><code>import httpx\nimport time\n\n# Replace with your Visionatrix server URL\nbase_url = \"http://localhost:8288\"\nusername = \"admin\"\npassword = \"admin\"\n\n\ndef create_sdxl_lighting_task():\n    # Task parameters\n    params = {\n        'prompt': 'A beautiful sunset over the mountains',\n        'steps_number': '8 steps',\n        # 'negative_prompt' is optional\n        # 'negative_prompt': 'blurry, low resolution',\n        # 'seed' is optional; if not specified, a random seed will be used\n        # 'seed': '12345',\n    }\n\n    # Convert parameters to the format expected by the 'files' parameter\n    files = {key: (None, value) for key, value in params.items()}\n\n    # Create the task\n    response = httpx.put(\n        f\"{base_url}/vapi/tasks/create/sdxl_lighting\",\n        auth=(username, password),\n        files=files\n    )\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        data = response.json()\n        task_ids = data.get('tasks_ids', [])\n        if task_ids:\n            task_id = task_ids[0]\n            print(\"Task created successfully. Task ID:\", task_id)\n            return task_id\n        else:\n            print(\"No task ID returned.\")\n    else:\n        print(\"Failed to create task:\", response.text)\n    return None\n\n\ndef check_task_progress(task_id):\n    while True:\n        response = httpx.get(\n            f\"{base_url}/vapi/tasks/progress/{task_id}\",\n            auth=(username, password)\n        )\n\n        if response.status_code == 200:\n            task_details = response.json()\n            progress = task_details.get('progress', 0)\n            error = task_details.get('error', '')\n            print(f\"Task {task_id} progress: {progress}%\")\n            if error:\n                print(f\"Task {task_id} encountered an error: {error}\")\n                return None\n            if progress &gt;= 100:\n                print(\"Task completed.\")\n                outputs = task_details.get('outputs', [])\n                return outputs  # Return outputs to avoid additional server call\n        else:\n            print(\"Failed to get task progress:\", response.text)\n            return None\n\n        # Wait before polling again\n        time.sleep(5)\n\n\ndef retrieve_task_results(task_id, outputs):\n    if outputs:\n        for output in outputs:\n            node_id = output.get('comfy_node_id')\n            if node_id is not None:\n                # Retrieve the result for each output node\n                params = {\n                    'task_id': task_id,\n                    'node_id': node_id\n                }\n                result_response = httpx.get(\n                    f\"{base_url}/vapi/tasks/results\",\n                    auth=(username, password),\n                    params=params\n                )\n                if result_response.status_code == 200:\n                    # Save the result to a file\n                    result_filename = f\"result_{task_id}_{node_id}.png\"\n                    with open(result_filename, 'wb') as f:\n                        f.write(result_response.content)\n                    print(f\"Result saved to {result_filename}\")\n                else:\n                    print(f\"Failed to retrieve result for node {node_id}:\", result_response.text)\n            else:\n                print(\"Output node ID not found.\")\n    else:\n        print(\"No outputs found in task details.\")\n\n\ndef main():\n    task_id = create_sdxl_lighting_task()\n    if task_id:\n        outputs = check_task_progress(task_id)\n        if outputs is not None:\n            retrieve_task_results(task_id, outputs)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"IntegrationsManual/getting_started/#example-2-using-the-remove-background-birefnet-flow","title":"Example 2: Using the \"Remove Background (Birefnet)\" Flow","text":"<pre><code>import httpx\nimport time\n\n# Replace with your Visionatrix server URL\nbase_url = \"http://localhost:8288\"\nusername = \"admin\"\npassword = \"admin\"\ninput_image_path = \"image.jpg\"\n\n\ndef create_remove_background_task():\n    # Open the image file in binary mode\n    with open(input_image_path, 'rb') as image_file:\n        files = {\n            'input_image': image_file\n        }\n\n        # Create the task\n        response = httpx.put(\n            f\"{base_url}/vapi/tasks/create/remove_background_birefnet\",\n            auth=(username, password),\n            files=files\n        )\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        data = response.json()\n        task_ids = data.get('tasks_ids', [])\n        if task_ids:\n            task_id = task_ids[0]\n            print(\"Task created successfully. Task ID:\", task_id)\n            return task_id\n        else:\n            print(\"No task ID returned.\")\n    else:\n        print(\"Failed to create task:\", response.text)\n    return None\n\n\ndef check_task_progress(task_id):\n    while True:\n        response = httpx.get(\n            f\"{base_url}/vapi/tasks/progress/{task_id}\",\n            auth=(username, password)\n        )\n\n        if response.status_code == 200:\n            task_details = response.json()\n            progress = task_details.get('progress', 0)\n            error = task_details.get('error', '')\n            print(f\"Task {task_id} progress: {progress}%\")\n            if error:\n                print(f\"Task {task_id} encountered an error: {error}\")\n                return None\n            if progress &gt;= 100:\n                print(\"Task completed.\")\n                outputs = task_details.get('outputs', [])\n                return outputs  # Return outputs to avoid additional server call\n        else:\n            print(\"Failed to get task progress:\", response.text)\n            return None\n\n        # Wait before polling again\n        time.sleep(5)\n\n\ndef retrieve_task_results(task_id, outputs):\n    if outputs:\n        for output in outputs:\n            node_id = output.get('comfy_node_id')\n            if node_id is not None:\n                # Retrieve the result for each output node\n                params = {\n                    'task_id': task_id,\n                    'node_id': node_id\n                }\n                result_response = httpx.get(\n                    f\"{base_url}/vapi/tasks/results\",\n                    auth=(username, password),\n                    params=params\n                )\n                if result_response.status_code == 200:\n                    # Save the result to a file\n                    result_filename = f\"result_{task_id}_{node_id}.png\"\n                    with open(result_filename, 'wb') as f:\n                        f.write(result_response.content)\n                    print(f\"Result saved to {result_filename}\")\n                else:\n                    print(f\"Failed to retrieve result for node {node_id}:\", result_response.text)\n            else:\n                print(\"Output node ID not found.\")\n    else:\n        print(\"No outputs found in task details.\")\n\n\ndef main():\n    task_id = create_remove_background_task()\n    if task_id:\n        outputs = check_task_progress(task_id)\n        if outputs is not None:\n            retrieve_task_results(task_id, outputs)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Notes:</p> <ul> <li>Replace <code>base_url</code> with your actual Visionatrix server URL if it's different.</li> <li>For the second example, replace <code>input_image_path</code> with the path to your input image file. Ensure that the file exists at the specified path.</li> <li>When creating a task, the API expects a <code>PUT</code> request with <code>multipart/form-data</code>. Therefore, even if you are not uploading any files (as in the <code>sdxl_lighting</code> flow), you should use <code>files=params</code> to ensure the request uses the correct content type.</li> <li>These scripts include basic error handling and polling logic.</li> <li>The <code>check_task_progress</code> function polls the task progress every 5 seconds. Adjust the sleep time as needed.</li> <li>The <code>retrieve_task_results</code> function uses the <code>outputs</code> obtained from the <code>check_task_progress</code> function, avoiding an additional call to the server.</li> <li>The result files are saved in the current working directory with filenames that include the task ID and node ID.</li> <li>Ensure that the required flows (<code>sdxl_lighting</code> and <code>remove_background_birefnet</code>) are installed on your Visionatrix instance before running these scripts.</li> <li>Additional optional parameters like <code>webhook_url</code>, <code>translate</code>, <code>group_scope</code>, <code>seed</code>, etc., are available but are not covered in this beginner guide.</li> </ul>"}]}